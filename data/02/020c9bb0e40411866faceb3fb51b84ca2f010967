<p>This is more of a maintenance update. The main headline is the addition of an option to select a curl-based backend for those who may encounter networking issues. By default, ollama-buddy uses built-in low-level networking calls, but if you have network issues, you can now switch to curl!</p>
<figure><img src="https://emacs.dyerdwelling.family/ox-hugo/20250424085731-emacs--Ollama-Buddy-0-9-35-Grok-Gemini-Integration-Enhanced-Sessions.jpg" width="100%">
</figure>

<h2 id="0-dot-13-dot-1"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-06-21 Sat&gt; </span></span> <strong>0.13.1</strong></h2>
<p>Refactored content register processing to be more efficient and added a new Emacs package brainstorming prompt file.</p>
<h2 id="0-dot-13-dot-0"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-06-15 Sun&gt; </span></span> <strong>0.13.0</strong></h2>
<p>Added curl communication backend with fallback support</p>
<ul>
<li>Added ollama-buddy-curl.el as separate backend implementation</li>
<li>Implemented backend dispatcher system in ollama-buddy-core.el</li>
<li>Updated all async functions to use backend dispatcher</li>
<li>Added curl backend validation and testing functions</li>
<li>Maintained full compatibility with existing network process backend</li>
</ul>
<p>When building Emacs packages that communicate with external services, network connectivity can sometimes be a pain point. While Emacs&rsquo;s built-in <code>make-network-process</code> works great in most cases, some users have encountered issues on certain systems or network configurations. That&rsquo;s why now I have added a curl-based communication backend to give you an additional option, who knows, maybe it will solve your ollama communication issues!</p>
<p>The original ollama-buddy implementation relied exclusively on Emacs&rsquo;s native network process functionality. While this works well for most users, I occasionally heard from users who experienced network process failures/flakiness on certain systems.</p>
<p>Rather than trying to work around these edge cases in the network process code, I took a different approach: I added curl as an alternative communication backend! This gives users a battle-tested, widely-available HTTP client as a fallback option.</p>
<p>Users can enable the curl backend with a simple customization:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-elisp" data-lang="elisp"><span style="display:flex;"><span>(use-package ollama-buddy
</span></span><span style="display:flex;"><span>  :bind
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#34;C-c o&#34;</span> <span style="color:#f92672">.</span> ollama-buddy-menu)
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#34;C-c O&#34;</span> <span style="color:#f92672">.</span> ollama-buddy-transient-menu-wrapper)
</span></span><span style="display:flex;"><span>  :config
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">;; Load curl backend first</span>
</span></span><span style="display:flex;"><span>  (require <span style="color:#e6db74">&#39;ollama-buddy-curl</span> <span style="color:#66d9ef">nil</span> <span style="color:#66d9ef">t</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">;; Then set the backend</span>
</span></span><span style="display:flex;"><span>  (setq ollama-buddy-communication-backend <span style="color:#e6db74">&#39;curl</span>))
</span></span></code></pre></div><p>and then switch backends from the chat buffer <code>C-c e</code></p>
<p>The curl backend supports everything the network backend does:</p>
<ul>
<li>Real-time streaming responses</li>
<li>Vision model support with image attachments</li>
<li>File attachments and context</li>
<li>All Ollama API parameters</li>
<li>Multishot model sequences</li>
</ul>
<p>If curl is selected but not available, the system automatically falls back to the network process with a helpful warning message.</p>
<p>From a user perspective, the backend choice is largely transparent. The main indicators are:</p>
<ul>
<li>Status line shows <code>[C]</code> for curl or <code>[N]</code> for network</li>
<li>Process list shows <code>ollama-chat-curl</code> vs <code>ollama-chat-stream</code> processes</li>
<li>Curl backend shows &ldquo;Curl Processing&hellip;&rdquo; in status messages</li>
</ul>
<p>Everything else - streaming behaviour, response formatting, error handling - works identically regardless of the backend.</p>
<h2 id="0-dot-12-dot-1"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-05-31 Sat&gt; </span></span> <strong>0.12.1</strong></h2>
<p>Optimized Unicode escape function to fix blocking with large file attachments</p>
<ul>
<li>Fixed UI blocking when sending large attached files</li>
<li>Used temp buffer with delete-char/insert instead of repeated concat calls</li>
<li>Reduced processing time from minutes to milliseconds for large payloads</li>
</ul>