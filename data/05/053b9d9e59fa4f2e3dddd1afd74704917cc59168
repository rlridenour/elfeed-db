<p>One of the features I’m hoping will be introduced next week at WWDC is <a href="https://www.bloomberg.com/news/articles/2025-05-20/apple-to-open-ai-models-to-developers-betting-that-it-will-spur-new-apps">Apple giving app developers access to its AI models</a>. Yes, Apple’s models need to improve, and hopefully we’ll hear something about that. But right now, only Apple really gets to use them (or package them up in features like Writing Tools and let apps access them in a one-size-fits-all way).</p>
<p>If app developers were to get full access to the models, though, it allows them to get creative in applying AI features inside their individual apps. Yes, app developers can add AI functionality to their apps today, but it would be a lot easier and more economical if they could rely on an Apple-approved set of models that run entirely for free.</p>
<p>There are a lot of possibilities. I keep dreaming about one that would allow the authors of podcast apps to use on-device transcription models to generate podcast transcripts on device and then upload the result to build a shared cloud database of transcripts to compete with the cloud-based catalogs of transcripts built by deep-pocketed companies like Apple. Social-media apps could automatically <a href="https://developers.google.com/ml-kit/genai/image-description/android">generate image descriptions</a> for uploaded images.</p>
<p>Another benefit would be the ability for apps to quickly generate AI summaries. I know there are limits to AI summaries—<a href="https://sixcolors.com/post/2025/01/apple-intelligence-summaries-might-get-warning-labels-thats-not-enough/">just ask the BBC</a>—but there are a lot of interface elements that could be helped by a quick one-line summary of content.</p>
<p>And then there’s a really exciting one, <a href="https://sixcolors.com/post/2024/01/artifacts-killer-feature-was-rewriting-bad-headlines/">pioneered by the now-defunct app Artifact</a>, which would allow RSS readers and similar apps to look at a story’s content and summarize it, perhaps even <a href="https://sixcolors.com/post/2025/01/llms-arent-always-bad-at-writing-news-headlines/">rewriting a clickbait headline</a>, so that it serves the reader rather than the publisher.</p>
<p>It’s all theoretical for now, and Apple’s models will need to be up to the challenge, but as <a href="https://stratechery.com/2025/apple-ais-platform-pivot-potential/">Ben Thompson wrote back in March</a>:</p>
<blockquote><p>
  What Apple should do instead is make its models — both local and in Private Cloud Compute — fully accessible to developers to make whatever they want. Don’t limit them to cutesy-yet-annoying frameworks like Genmoji or sanitized-yet-buggy image generators, and don’t assume that the only entity that can create something compelling using developer data is the developer of Siri; instead return to the romanticism of platforms: enabling users and developers to make things completely unforeseen. This is something only Apple could do, and, frankly, it’s something the entire AI industry needs.
</p></blockquote>
<p>Yes. This please.</p>
