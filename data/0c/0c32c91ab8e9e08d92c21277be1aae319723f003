
        <p>:: <span class="label">Tags:</span> <span role="list" aria-label="Tags for â€œYou Wouldn&#39;t Sudo a Stranger&#39;s Code Would You?â€">
<span role="listitem" aria-label="&ldquo;llms&rdquo; tag navigation"><a href="https://takeonrules.com/2025/04/12/raiding-parties/" aria-label="Previous post tagged with &ldquo;llms&rdquo; is &ldquo;Raiding Parties&rdquo;" title="Older post tagged with &ldquo;llms&rdquo; is &ldquo;Raiding Parties&rdquo;"><small>&lt;</small></a>
<a href="https://takeonrules.com/tags/llms/" class="p-category" aria-label="All posts tagged with &ldquo;llms&rdquo;" title="All posts tagged with &ldquo;llms&rdquo;">llms</a> <a href="https://takeonrules.com/2025/08/04/seeking-truth-and-avoiding-error/" aria-label="Next post tagged with &ldquo;llms&rdquo; is &ldquo;Seeking Truth and Avoiding Error&rdquo;" title="Newer post tagged with &ldquo;llms&rdquo; is &ldquo;Seeking Truth and Avoiding Error&rdquo;"><small>&gt;</small></a>
</span><span aria-hidden=true> &middot; </span>
<span role="listitem" aria-label="&ldquo;responses&rdquo; tag navigation"><a href="https://takeonrules.com/2025/05/23/reading-through-a-hard-to-read-chapter/" aria-label="Previous post tagged with &ldquo;responses&rdquo; is &ldquo;Reading Through a Hard to Read Chapter&rdquo;" title="Older post tagged with &ldquo;responses&rdquo; is &ldquo;Reading Through a Hard to Read Chapter&rdquo;"><small>&lt;</small></a>
<a href="https://takeonrules.com/tags/responses/" class="p-category" aria-label="All posts tagged with &ldquo;responses&rdquo;" title="All posts tagged with &ldquo;responses&rdquo;">responses</a> <a href="https://takeonrules.com/2025/06/08/when-no-thing-works-by-norma-kawelok%C5%AB-wong/" aria-label="Next post tagged with &ldquo;responses&rdquo; is &ldquo;â€œWhen No Thing Worksâ€ by Norma KawelokÅ« Wong&rdquo;" title="Newer post tagged with &ldquo;responses&rdquo; is &ldquo;â€œWhen No Thing Worksâ€ by Norma KawelokÅ« Wong&rdquo;"><small>&gt;</small></a>
</span></span>

</><p><strong>Summary: </strong>
Thinking through further reasons why I&rsquo;m less and less likely to use #AI (aka an #LLM).
</p>
        <p>I was reading <a href="https://200ok.ch/posts/2025-05-23_sandboxing_ai_tools:_how_guix_containers_keep_your_host_safe_while_empowering_llms.html">200ok: Sandboxing AI Tools: How Guix Containers Keep Your Host
Safe While Empowering LLMs</a> and their opening passage struck me; I re-read it in
the voice of those â€œYou wouldnâ€™t steal a car would you?â€ commercials from the
music industry.</p>

<blockquote  class="h-cite">

<p>Picture this: You&rsquo;re deep in a coding session with an <span>Large Language Model</span> (<abbr title="Large Language Model">LLM</abbr> <small><a class="ref" rel="tag opener" aria-label="Other site-wide references of â€œLarge Language Modelâ€" title="Other site-wide references of â€œLarge Language Modelâ€" href="https://takeonrules.com/site-map/glossary/#abbr-dfn-GLOSSARY-LLM">ğŸ“–</a></small>)
, and your <span><a href="https://en.wikipedia.org/wiki/Artificial_intelligence_in_fiction">Artificial Intelligence</a></span> (<abbr title="Artificial Intelligence">AI</abbr> <small><a class="ref" rel="tag opener" aria-label="Other site-wide references of â€œArtificial Intelligenceâ€" title="Other site-wide references of â€œArtificial Intelligenceâ€" href="https://takeonrules.com/site-map/glossary/#abbr-dfn-GLOSSARY-AI">ğŸ“–</a></small>)
assistant
suggests running some shell commands or manipulating files. It&rsquo;s incredibly
productiveâ€”until that nagging voice in your head whispers, &ldquo;What if this goes
wrong?&rdquo;</p>
<p>We&rsquo;ve all been there. AI tools with filesystem and command execution
capabilities are absolute game-changers for productivity, but handing over the
keys to your entire system? That&rsquo;s a hard pass for any security-conscious
developer.</p>


</blockquote>

<p>First, I canâ€™t picture it.  I rarely use an <abbr title="Large Language Model">LLM</abbr>
.  It is absolutely not an
integrated part of my workâ€”I donâ€™t need some roid-raging Clippy brow beating me
with constant revisions nor teasing me with short-cuts that cobble together a
Frankensteinâ€™s monster.</p>
<p>Second, â€œhanding over keys to your entire system?â€  Yes that is a hard pass.  I
see <abbr title="Artificial Intelligence">AI</abbr>
 (as presented) as handing over keys to a superset of the system implied
by the original poster; namely the system of skill development.</p>
<p>I think to the hierarchy of survival in an emergency: tools are the most
important, then skills, then relationships.  However, once an emergency abates,
the order flips: relationships being the most important, then skills, and
finally tools.</p>
<p>I see <abbr title="Artificial Intelligence">AI</abbr>
 (as presented) as a toolâ€¦that you lease/rent; one that comes loaded
with an agenda of its creator(s).  And looking to that order outside of an
emergency, replacing skill development and usage with using a leased non-neutral
tool creates a precarity Iâ€™m not prepared to accept for myself.</p>
<p>Getting better and more dependent on a leased/rented tool makes little sense,
unless Iâ€™m prepared to cede my means of production to the owner of that tool.</p>

	<p><a class="reply-by-email" href="mailto:reply-to@takeonrules.com?subject=RE:You%20Wouldn%27t%20Sudo%20a%20Stranger%27s%20Code%20Would%20You%3f">Reply by Email</a></p>

      