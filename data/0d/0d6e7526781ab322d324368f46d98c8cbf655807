<p>In this era of AI, &#8220;can we still rely on take-home writing assignments to assess student learning? And, should we allow students to use ChatGPT in order to complete such assignments? My answer to both questions is &#8216;yes&#8217;.&#8221;<span id="more-55107"></span></p>
<p>That is <a href="https://explanations.ai/" target="_blank" rel="noopener">Carlos Zednik</a>, assistant professor of philosophy at <a href="https://www.tue.nl/en/research/research-groups/innovation-sciences/philosophy-ethics/" target="_blank" rel="noopener">Eindhoven University of Technology</a> and director of the <a href="https://www.ephil.ai/" target="_blank" rel="noopener">Eindhoven Center for Philosophy of AI</a>.</p>
<p>He has observed AI-assisted philosophical writing in hundreds of students, developed a version of prompt-grading as an assessment method, and gathered some evidence that shows that &#8220;prompt grades appear to be sufficiently valid as a measure of philosophical knowledge and argumentative skill, at least insofar as they track more traditional measures such as essay grades.&#8221;</p>
<p>His conclusion is that philosophical essays can still be valuable pedagogical tools if they are assigned and graded by professors who understand the technology their students are using.</p>
<hr />
<div id="attachment_55145" style="width: 714px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-55145" class="size-full wp-image-55145" src="https://dailynous.com/wp-content/uploads/2025/09/de-chirico-giorgio-the-faithful-servant.jpg" alt="" width="704" height="777" srcset="https://dailynous.com/wp-content/uploads/2025/09/de-chirico-giorgio-the-faithful-servant.jpg 704w, https://dailynous.com/wp-content/uploads/2025/09/de-chirico-giorgio-the-faithful-servant-272x300.jpg 272w, https://dailynous.com/wp-content/uploads/2025/09/de-chirico-giorgio-the-faithful-servant-400x441.jpg 400w" sizes="auto, (max-width: 704px) 100vw, 704px" /><p id="caption-attachment-55145" class="wp-caption-text">[Giorgio de Chirico, &#8220;The Faithful Servant&#8221;]</p></div>
<h2 style="text-align: center;">Grading Prompts to Measure Student Learning<br />
<em><strong>by Carlos Zednik</strong></em></h2>
<p>Ever since its release in November 2022, university instructors have worried about ChatGPT’s impact on higher education. The situation is particularly worrisome in disciplines like philosophy, which traditionally rely on take-home writing assignments to promote and assess student learning. Students are expected to write in order to acquire philosophical knowledge and argumentative skill, and teachers are expected to read their students’ written products in order to measure their learning progress. However, now that large language models can be prompted to generate argumentative essays, ethical analyses, and reading-responses, commentators have begun to question the value of asking students to produce these kinds of written products—and of asking teachers to grade them. Is the <a href="https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/">college essay really dead</a>?</p>
<p>Let’s get something out of the way first: There can be no doubt that generative AI technology has reached a level of sophistication at which students can use it to produce excellent pieces of philosophical writing. Long gone (on AI time scales) are the days when AI-generated essays could be reliably distinguished from mid-level undergraduate work. Moreover, recent releases of “reasoning models” by OpenAI, DeepSeek, and others—whose internal processes can be visualized in <a href="https://arxiv.org/abs/2201.11903">“chain of thought” mode</a>—reveal sophisticated patterns of argumentation, analysis, and knowledge-integration that rival those of advanced graduate students, and perhaps even of professional philosophers. Although these systems’ written products are fallible and prone to hallucination and bias, they are arguably no more imperfect than their human-produced analogues.</p>
<p>Just as students would appear foolish not to take advantage of machines that can do their homework for them, teachers would appear to be selling themselves short by tediously commenting and evaluating hundreds of pages of <a href="https://www.sciencedirect.com/science/article/abs/pii/S0007681324000272">botshit content</a> every semester. So, can we still rely on take-home writing assignments to assess student learning? And, should we allow students to use ChatGPT in order to complete such assignments?</p>
<p>My answer to both questions is “yes”. Indeed, for just over two years, I have permitted unrestricted use of AI in my own Bachelor and Master’s-level philosophy courses at Eindhoven University of Technology, without worrying that students are failing to acquire relevant knowledge and skills, and without feeling that my efforts are lacking in value. On the contrary, by allowing students to use generative AI when they write, I believe to be providing them with a uniquely appropriate kind of preparation for their future lives and careers in an AI-assisted world. At the same time, by asking students to keep a detailed record of their AI-use, I have a privileged glimpse into a new but increasingly commonplace way of working, creating, and thinking.</p>
<p>Whereas traditional assessment methods in university-level philosophy courses center on the written product—the completed essay, report, or analysis—I now instead focus on the writing process—the way in which students interact with generative AI systems such as ChatGPT to complete a piece of philosophical writing. A student’s interaction with generative AI centers on their use of prompts: inputs that are designed to maximize the correctness, relevance, effectiveness, beauty, desirability, or (more generally) appropriateness of the AI system’s outputs. Of course, “prompt engineering” is among the buzziest of buzzwords on YouTube, TikTok, and LinkedIn—all of which feature lengthy tutorials on prompting frameworks such as <a href="https://kylebalmer.com/index.php/2024/11/13/prompt-playbook-blueprint-prompts-part-2/">RISEN</a> (Role, Instruction, Steps, End goal, Narrowing). If mastered, such frameworks can help students prompt ChatGPT to produce text that satisfies the constraints of any assignment description (or, for that matter, to complete almost any other task that would traditionally be completed by a human working on a computer).</p>
<p>I have no intention of evaluating students’ mastery of prompting frameworks—I teach philosophy, not prompt engineering. That said, what regularly gets lost in discussions of generative AI and its impact on the classroom is the fact that good prompting is not merely a technical skill, captured in the principles of a domain-general prompting framework, but that it also requires domain-specific knowledge to precisely define and narrow the context that constrains an AI system’s outputs. Indeed, specifying context in prompts is critical for generating content: ChatGPT produces exactly those outputs that it estimates to be the most likely to occur within the context of its inputs. Insofar as likelihood is a proxy for appropriateness, the more narrowly the context is specified, the more appropriate the generated outputs are going to be. Specifying the right context for a particular task—writing, drawing, video-making, computer programming, tax-filing, or restaurant-reservation-making—is tricky, and may require a human prompter to appeal to prior knowledge, deploy domain-relevant skill, and to critically, creatively, and repeatedly engage with a system in order to evaluate, select, and tweak the content being generated.</p>
<p>Consider two illustrative examples. Although influential AI artists such as <a href="https://refikanadol.com/">Refik Anadol</a> use state-of-the-art image generators such as StableDiffusion or MidJourney to produce compelling art, they do so through an iterative process of prompting, selecting, cropping, editing, and re-prompting that requires a considerable amount of experience, skill, and aesthetic sensibility. Similarly, although AI-assisted <a href="https://en.wikipedia.org/wiki/Vibe_coding">vibe-cod</a><a href="https://en.wikipedia.org/wiki/Vibe_coding">ers</a> allow generative AI systems to take care of the syntax of a computer program while they focus on defining the task specifications, supervising the logic, and ensuring the correctness of the program’s semantics, these latter kinds of activities still benefit from programming experience, domain knowledge, and coding ingenuity. The point is not that AI systems cannot be prompted to generate art or computer code with relatively little effort, but rather that (assuming similar levels of prompt-engineering mastery) domain-experts are likely to generate better final products than novices. The reason for this is that experts are better able to define and narrow the context within the prompts that are used to generate content.</p>
<p>AI-assisted philosophical writing is no different. Whereas the use of domain-general prompt-engineering principles may allow an ill-informed and disengaged student to generate a passable piece of philosophical writing solely on the basis of their prompt-engineering chops, that piece will compare unfavorably to one that is generated by a student who suitably narrows the context by introducing relevant philosophical knowledge and argumentative skill into their prompts.</p>
<p>Let us look a bit more closely at the process of AI-assisted philosophical writing as I have seen it unfold in the prompts of several hundred Bachelor and Master’s students in Eindhoven. Almost all students use generative AI to research ideas as well as to summarize lecture slides, news articles, and assigned readings. They prompt ChatGPT to brainstorm possible solutions to moral problems, and to come up with counterexamples and objections to philosophical claims. They may of course ask the system to generate arguments in support of a particular claim, or to provide empirical, textual, or logical evidence in support of a particular premise. In their interactions with generative AI, students also often introduce technical course concepts from the lectures or readings, and ask the AI system to reflect on, define, or apply these concepts. They might also prompt a system to analyze a case study from the perspective of a particular ethical theory, or to apply the distinctions or frameworks championed by a particular philosopher. Of course, after having done all of these things and more, students prompt the system to generate complete sentences, paragraphs, or sections which they go on to copy-paste, review, tweak, and ultimately submit.</p>
<div id="attachment_55108" style="width: 910px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-55108" class=" wp-image-55108" src="https://dailynous.com/wp-content/uploads/2025/09/zednik-annotated_prompt2-1024x394.png" alt="" width="900" height="346" srcset="https://dailynous.com/wp-content/uploads/2025/09/zednik-annotated_prompt2-1024x394.png 1024w, https://dailynous.com/wp-content/uploads/2025/09/zednik-annotated_prompt2-300x116.png 300w, https://dailynous.com/wp-content/uploads/2025/09/zednik-annotated_prompt2-768x296.png 768w, https://dailynous.com/wp-content/uploads/2025/09/zednik-annotated_prompt2-1536x591.png 1536w, https://dailynous.com/wp-content/uploads/2025/09/zednik-annotated_prompt2-400x154.png 400w, https://dailynous.com/wp-content/uploads/2025/09/zednik-annotated_prompt2.png 1631w" sizes="auto, (max-width: 900px) 100vw, 900px" /><p id="caption-attachment-55108" class="wp-caption-text">Example of a prompt used by a student to write an argumentative essay in a 2024-2025 Master’s-level “Philosophy and Ethics of AI” course at Eindhoven University of Technology, on whether rule-based symbol-manipulation is sufficient for intelligence. Annotations highlight some of the philosophical knowledge and argumentative skill being deployed in a ChatGPT prompt. This knowledge and skill narrows the context for the AI system’s response, and is indicative of the student’s learning.</p></div>
<p>I don’t consider these interactions to be evidence of cheating. Rather, I take them as demonstrations of the kind of knowledge and skill that is required to build a compelling philosophical argument or ethical analysis, albeit with the help of an AI-powered computer. A student’s ability to produce high quality work depends not only on their mastery of RISEN, but also on their ability to deploy philosophical knowledge and argumentative skill in their prompts. By inspecting these prompts for evidence of such knowledge and skill, teachers can assess their students’ and assign a meaningful grade.</p>
<p>How effective is prompt-grading as an assessment method? As we report in a current preprint, <a href="https://osf.io/preprints/psyarxiv/cne9j_v3">t</a><a href="https://osf.io/preprints/psyarxiv/cne9j_v3">he </a><a href="https://osf.io/preprints/psyarxiv/cne9j_v3">initial results are promising</a>. For one, students who demonstrate philosophical knowledge and argumentative skill in their prompts produce better philosophical writing (i.e., they receive a better essay grade) than their peers who do not. Moreover, they produce better philosophical writing than students who only or primarily employ domain-general prompt-engineering principles, and do better than students who who merely use AI to improve linguistic “surface features” such as spelling, grammar, word choice, and style. Thus, prompt grades appear to be sufficiently valid as a measure of philosophical knowledge and argumentative skill, at least insofar as they track more traditional measures such as essay grades.</p>
<p>For another, different teachers grade prompts similarly. Whereas I initially was the only instructor daft enough to sift through 100-page ChatGPT interaction logs (a process that now takes me approximately 15 minutes per student, which I deem to be acceptable), the efforts of additional graders resulted in sufficiently low between-grader variability. To this end, efforts were made to ensure consistency between graders by defining a prompt-grading rubric, explaining to students what kinds of things would be rewarded during the prompt-grading process, and by applying a standard prompt taxonomy to help graders classify and evaluate prompts according to their relevance and quality within the context of philosophical essay-writing. Thus, prompt-grading appears to be not only valid as a measure of philosophical knowledge and argumentative skill, it also appears to be reliable.</p>
<p>Given this preliminary evidence, I recommend taking seriously the idea that a student’s philosophical knowledge and argumentative skill can be assessed by evaluating the quality of the prompts they use to complete take-home philosophical writing tasks. This form of assessment can be implemented by requiring students to submit complete interaction logs that contain all prompts and AI-generated responses, and by asking teachers to evaluate these logs systematically, using a grading rubric and prompt taxonomy. A student’s interaction log can be graded, and that grade can be combined with a grade for the final essay or report to yield a combined measure of writing process and written product.</p>
<p>Of course, I do not believe that prompt-grading should be the only measure of student learning. The ability to contribute to in-class discussions, or to produce philosophical writing without external aid, continue to be effective measures of relevant knowledge and skill. Moreover, I also do not believe that prompt-grading is a perfect measure. In particular, it is not entirely immune to the worry that AI technology might allow students to pretend to know things they do not. Recent research on <a href="https://github.com/suzgunmirac/meta-prompting">meta-prompting</a>—training AI systems to generate prompts—suggests that enterprising students may use AI not only to generate philosophical writing, but to also generate the prompts with which to do so. That said, although I cannot predict the future, I am cautiously optimistic that even meta-prompting would benefit from the insertion of relevant knowledge and skill that could in principle be evaluated.</p>
<p>In conclusion, reports of death of the college essay appear greatly exaggerated. Certainly, ChatGPT poses a challenge. As is always the case, however, the challenge comes with an opportunity. In this case, the opportunity is to let students actively explore the limits of this powerful new tool, all the while teaching them to use it reflectively and responsibly.</p><p>The post <a href="https://dailynous.com/2025/09/30/grading-prompts-to-measure-student-learning-guest-post/">Grading Prompts to Measure Student Learning (guest post)</a> first appeared on <a href="https://dailynous.com">Daily Nous</a>.</p>