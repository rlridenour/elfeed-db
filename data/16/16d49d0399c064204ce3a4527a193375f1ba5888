<p>Several improvements in the latest Ollama Buddy updates (versions 0.9.21 through 0.9.35):</p>
<figure><img src="https://emacs.dyerdwelling.family/ox-hugo/20250424085731-emacs--Ollama-Buddy-0-9-35-Grok-Gemini-Integration-Enhanced-Sessions.jpg" width="100%">
</figure>

<h2 id="new-ai-integrations-with-grok-and-gemini">üéâ New AI Integrations with Grok and Gemini</h2>
<ul>
<li>Google&rsquo;s Gemini is now complementing existing support for Claude, ChatGPT (OpenAI), and Ollama models. Setting up is straightforward and consistent with other integrations.</li>
<li>Just like the existing integrations, Grok can now be easily configured with your API key.</li>
</ul>
<!--more-->
<h2 id="improved-remote-llm-architecture">üîó Improved Remote LLM Architecture</h2>
<p>LLM internal decoupling, making Ollama Buddy&rsquo;s core logic independent from any specific remote LLM. Each LLM integration now functions as a self-contained extension, significantly simplifying future additions and maintenance.</p>
<h2 id="standardized-model-prefixing">üéØ Standardized Model Prefixing</h2>
<p>Now there are more remote LLMs into the mix I thought it was probably time to more clearly distinguish between model collections, so I have defined the following prefixes:</p>
<ul>
<li>Ollama:  <code>o:</code></li>
<li>ChatGPT: <code>a:</code></li>
<li>Claude:  <code>c:</code></li>
<li>Gemini:  <code>g:</code></li>
<li>Grok:    <code>k:</code></li>
</ul>
<p>This change helps ensure clarity, especially when recalling previous sessions. Note: existing session files will need the Ollama prefix (<code>o:</code>) added manually if you encounter issues recalling older sessions.</p>
<h2 id="enhanced-session-management">üíæ Enhanced Session Management</h2>
<p>Saving session now makes a little more sense and is more consistent:</p>
<ul>
<li>Automatic timestamped session names (you can still set your own).</li>
<li>Sessions now also save as <code>org</code> files alongside the original <code>elisp</code> files, allowing for richer recall and easy inspection later.</li>
<li>The current session name appears dynamically in your modeline, offering quick context.</li>
</ul>
<h2 id="Ô∏è-additional-improvements">üõ†Ô∏è Additional Improvements</h2>
<ul>
<li>UTF-8 encoding fixes for remote LLM stream responses.</li>
<li>Refactored history and model management so all the latest models are available for selection.  This is currently most relevant for remote LLMs which often change their model selection.</li>
<li>History view/edit functionality merged into one keybinding</li>
</ul>
<hr>
<p>and here is the change history</p>
<h2 id="0-dot-9-dot-35"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-21 Mon&gt; </span></span> <strong>0.9.35</strong></h2>
<p>Added Grok support</p>
<p>Integration is very similar to other remote AIs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-elisp" data-lang="elisp"><span style="display:flex;"><span>(use-package ollama-buddy
</span></span><span style="display:flex;"><span>  :bind
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#34;C-c o&#34;</span> <span style="color:#f92672">.</span> ollama-buddy-menu)
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#34;C-c O&#34;</span> <span style="color:#f92672">.</span> ollama-buddy-transient-menu-wrapper)
</span></span><span style="display:flex;"><span>  :custom
</span></span><span style="display:flex;"><span>  (ollama-buddy-grok-api-key
</span></span><span style="display:flex;"><span>   (auth-source-pick-first-password :host <span style="color:#e6db74">&#34;ollama-buddy-grok&#34;</span> :user <span style="color:#e6db74">&#34;apikey&#34;</span>))
</span></span><span style="display:flex;"><span>  :config
</span></span><span style="display:flex;"><span>  (require <span style="color:#e6db74">&#39;ollama-buddy-grok</span> <span style="color:#66d9ef">nil</span> <span style="color:#66d9ef">t</span>))
</span></span></code></pre></div><h2 id="0-dot-9-dot-33"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-20 Sun&gt; </span></span> <strong>0.9.33</strong></h2>
<p>Fixed utf-8 encoding stream response issues from remote LLMs.</p>
<h2 id="0-dot-9-dot-32"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-19 Sat&gt; </span></span> <strong>0.9.32</strong></h2>
<p>Finished the remote LLM decoupling process, meaning that the core <code>ollama-buddy</code> logic is now not dependent on any remote LLM, and each remote LLM package is self-contained and functions as a unique extension.</p>
<h2 id="0-dot-9-dot-31"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-18 Fri&gt; </span></span> <strong>0.9.31</strong></h2>
<p>Refactored model prefixing logic and cleaned up</p>
<ul>
<li>Standardized model prefixing by introducing distinct prefixes for Ollama (<code>o:</code>), OpenAI (<code>a:</code>), Claude (<code>c:</code>), and Gemini (<code>g:</code>) models.</li>
<li>Centralized functions to get full model names with prefixes across different model types.</li>
<li>Removed redundant and unused variables related to model management.</li>
</ul>
<p>Note that there may be some breaking changes here especially regarding session recall as all models will now have a prefix to uniquely identify their type.  For <code>ollama</code> recall, just edit the session files to prepend the ollama prefix of &ldquo;o:&rdquo;</p>
<h2 id="0-dot-9-dot-30"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-17 Thu&gt; </span></span> <strong>0.9.30</strong></h2>
<p>Added Gemini integration!</p>
<p>As with the Claude and ChatGPT integration, you will need to add something similar to them in your configuration. I currently have the following set up to enable access to the remote LLMs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-elisp" data-lang="elisp"><span style="display:flex;"><span>(use-package ollama-buddy
</span></span><span style="display:flex;"><span>  :bind
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#34;C-c o&#34;</span> <span style="color:#f92672">.</span> ollama-buddy-menu)
</span></span><span style="display:flex;"><span>  (<span style="color:#e6db74">&#34;C-c O&#34;</span> <span style="color:#f92672">.</span> ollama-buddy-transient-menu-wrapper)
</span></span><span style="display:flex;"><span>  :custom
</span></span><span style="display:flex;"><span>  (ollama-buddy-openai-api-key
</span></span><span style="display:flex;"><span>   (auth-source-pick-first-password :host <span style="color:#e6db74">&#34;ollama-buddy-openai&#34;</span> :user <span style="color:#e6db74">&#34;apikey&#34;</span>))
</span></span><span style="display:flex;"><span>  (ollama-buddy-claude-api-key
</span></span><span style="display:flex;"><span>   (auth-source-pick-first-password :host <span style="color:#e6db74">&#34;ollama-buddy-claude&#34;</span> :user <span style="color:#e6db74">&#34;apikey&#34;</span>))
</span></span><span style="display:flex;"><span>  (ollama-buddy-gemini-api-key
</span></span><span style="display:flex;"><span>   (auth-source-pick-first-password :host <span style="color:#e6db74">&#34;ollama-buddy-gemini&#34;</span> :user <span style="color:#e6db74">&#34;apikey&#34;</span>))
</span></span><span style="display:flex;"><span>  :config
</span></span><span style="display:flex;"><span>  (require <span style="color:#e6db74">&#39;ollama-buddy-openai</span> <span style="color:#66d9ef">nil</span> <span style="color:#66d9ef">t</span>)
</span></span><span style="display:flex;"><span>  (require <span style="color:#e6db74">&#39;ollama-buddy-claude</span> <span style="color:#66d9ef">nil</span> <span style="color:#66d9ef">t</span>)
</span></span><span style="display:flex;"><span>  (require <span style="color:#e6db74">&#39;ollama-buddy-gemini</span> <span style="color:#66d9ef">nil</span> <span style="color:#66d9ef">t</span>))
</span></span></code></pre></div><p>Also with the previous update all the latest model names will be pulled, so there should be a full comprehensive list for each of the main remote AI LLMs!</p>
<h2 id="0-dot-9-dot-23"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-16 Wed&gt; </span></span> <strong>0.9.23</strong></h2>
<p>Refactored history and model management for remote LLMs</p>
<ul>
<li>Now pulling in latest model list for remote LLMs (so now ChatGPT 4.1 is available!)</li>
<li>Removed redundant history and model management functions from <code>ollama-buddy-claude.el</code> and <code>ollama-buddy-openai.el</code>. Replaced them with shared implementations to streamline code and reduce duplication</li>
</ul>
<h2 id="0-dot-9-dot-22"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-15 Tue&gt; </span></span> <strong>0.9.22</strong></h2>
<p>Enhanced session management</p>
<ul>
<li>Refactored <code>ollama-buddy-sessions-save</code> to autogenerate session names using timestamp and model.</li>
<li>Improved session saving/loading by integrating org file handling.</li>
<li>Updated mode line to display current session name dynamically.</li>
</ul>
<p>Several improvements to session management, making it more intuitive and efficient for users. Here&rsquo;s a breakdown of the new functionality:</p>
<p>When saving a session, Ollama Buddy now creates a default name using the current timestamp and model name, users can still provide a custom name if desired.</p>
<p>An org file is now saved alongside the original elisp session file. This allows for better session recall as all interactions will be pulled back with the underlying session parameters still restored as before. There is an additional benefit in not only recalling precisely the session and any additional org interactions but also quickly saving to an org file for potential later inspection. Along with the improved autogenerated session name, this means it is much faster and more intuitive to save a snapshot of the current chat interaction.</p>
<p>The modeline now displays the current session name!</p>
<h2 id="0-dot-9-dot-21"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-04-11 Fri&gt; </span></span> <strong>0.9.21</strong></h2>
<p>Add history edit/view toggle features, so effectively merging the former history display into the history edit functionality.</p>