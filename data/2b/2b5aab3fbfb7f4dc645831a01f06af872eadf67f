<p>“I don’t want to be a cop in the classroom. So, it’s&#8230; important for students to come to the same conclusion themselves and <em>understand the rationale</em> for this [AI] policy.”<span id="more-54564"></span></p>
<p>Recently, <a href="https://philosophy.calpoly.edu/faculty/patrick-lin" target="_blank" rel="noopener">Patrick Lin</a>, a philosophy professor at Cal Poly, San Luis Obispo, wrote a long essay for his students on the importance of explaining to why artificial intelligence (AI) is prohibited in his courses. He also shared it on <a href="https://emergingethics.substack.com/" target="_blank" rel="noopener">his new Substack site</a> with the thought that it could be of use to other instructors in justifying an AI ban to their own students, “to help get their buy-in from the very start.”</p>
<p>In this guest post, Professor Lin offers a <em>meta</em>-discussion around the article, including questions about it that he’s been asked. It’s a timely follow-up to a <em>Daily Nous</em> <a href="https://dailynous.com/2025/07/25/if-you-dont-want-your-students-using-ai-on-work-you-assign/">conversation</a> last month about how to get students to do their coursework without the help of AI. His full article can be found <a href="https://emergingethics.substack.com/p/why-were-not-using-ai-in-this-course" target="_blank" rel="noopener">here</a>.</p>
<p>This is the eleventh post in the <a class="wp-dark-mode-bg-image" href="https://dailynous.com/tag/summer-guest-post-series-2025/">Summer 2025 Guest Post Series</a> at <em class="wp-dark-mode-bg-image">Daily Nous</em>. (As with the previous posts, it will be pinned to the top of site’s homepage for a few days.)</p>
<hr />
<div id="attachment_54565" style="width: 711px" class="wp-caption aligncenter"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-54565" class=" wp-image-54565" src="https://dailynous.com/wp-content/uploads/2025/08/frankenthaler-lighthouse-series-xi.jpg" alt="" width="701" height="499" srcset="https://dailynous.com/wp-content/uploads/2025/08/frankenthaler-lighthouse-series-xi.jpg 1952w, https://dailynous.com/wp-content/uploads/2025/08/frankenthaler-lighthouse-series-xi-300x214.jpg 300w, https://dailynous.com/wp-content/uploads/2025/08/frankenthaler-lighthouse-series-xi-1024x729.jpg 1024w, https://dailynous.com/wp-content/uploads/2025/08/frankenthaler-lighthouse-series-xi-768x547.jpg 768w, https://dailynous.com/wp-content/uploads/2025/08/frankenthaler-lighthouse-series-xi-1536x1094.jpg 1536w, https://dailynous.com/wp-content/uploads/2025/08/frankenthaler-lighthouse-series-xi-400x285.jpg 400w" sizes="auto, (max-width: 701px) 100vw, 701px" /><p id="caption-attachment-54565" class="wp-caption-text">[Helen Frankenthaler &#8211; Lighthouse Series XI]</p></div>
<h2 style="text-align: center;">How to Justify an AI Ban in Your Classroom<br />
<em><strong>by Patrick Lin</strong></em></h2>
<p>The new academic term is soon upon us, if not here already for some, and philosophers are still scrambling to sort out their classroom policies in light of rampant AI cheating. Do they fight the AI trend, or do they lean into it &#8212;that is, resistance or appeasement (or even assimilation)?</p>
<p>Either way could be ok, but both paths have risks and costs. If you have the time to <em>retool</em> your course to allow for AI use, then great, but are those new assignments pedagogically sound, considering most of us aren’t instructional technology &amp; design experts? Or if you just <em>ban </em>AI, how effective would that even be, and how do you get students to go along with the plan?</p>
<p>I chose the resistance path&#8212;to ban AI&#8212;as the path of least resistance, ironically. This seems appropriate, considering most of us are overworked and underpaid teachers who didn’t create this AI-cheating epidemic, and we’re typically not given resources by our schools to do much else about it.</p>
<p>But a big worry with this path is that it can change the teacher-student relationship for the worse. Many students will think a blanket ban is too dogmatic or strict, even <em>harmful</em> to their future, if it’ll be important to know how to use AI in the job market when they graduate. This can lead them to be resentful and disregard your ban out of spite, affecting their morale and how much they’ll get from your course.</p>
<p>My approach is two-pronged. Beside deterrence measures in the form of penalties, I also want to try <em>gentle persuasion</em> to get students on board with the AI policy. Once they understand the policy, the hope is that they’ll want to comply with it on their own, even without penalties. This isn’t just for the good of my own classroom; it would be helpful to a student’s entire academic career&#8212;and future&#8212;if they understand the value of putting in the work themselves and not using AI, especially when a course isn’t designed to handle AI.</p>
<p>I won’t attempt to summarize the article here, not least of all because it ended up being more than 12,000 words as a result of me trying to round up <em>all </em>the major concerns around AI use by students. (If I missed any big ones, feel free to let me know.) But in what follows I&#8217;ll point out a few issues in there that I haven’t seen discussed much elsewhere, but which could resonate with students.</p>
<p>In section 3 on &#8220;future risks&#8221;, I take seriously the popular assumption by AI enthusiasts and promoters that AI will do most or all of our jobs in the future, and we’ll just need to know how to use or “wrangle” AI. That seems to be a major belief behind the rationalization of AI cheating in school. If we take that premise seriously, what follows? I suggest that the premise leads to something like a <em>reductio ad absurdum&#8212;</em>it’s self-defeating:</p>
<p style="padding-left: 40px;">“Maybe that prediction is right, but it can’t possibly mean that you will <em>only </em>need to know how to use AI and little else. If that were the case, then companies can hire anyone, assuming they want to hire humans at all &#8212;and there’s no reason they would need to hire <em>you</em> specifically. AI wranglers are (or will be) a dime a dozen and don’t require any expertise or educational background. With such a huge <em>oversupply of interchangeable AI wranglers</em>, the pay scale would be miserable.”</p>
<p>Relatedly, there’s a growing chorus of calls for teachers to integrate AI into their classes because knowing how to use AI will be vital in the future, or so the prediction goes. But:</p>
<p style="padding-left: 40px;">“Even if it’s important to learn how to use AI in this brave new world, <em>it’s not clear that the typical university course is the place to do it</em>, much less a <em>philosophy </em>course &#8230; Think about the other technologies that modern workers need to know, such as office applications (word processing, spreadsheets, presentation slides, etc.). Can you name a university course that has an objective of learning how to use those technologies? Unless the course itself is an introduction to computers or office technologies, the learning objectives would usually be related to the course’s subject itself, philosophy in our case, and not on general life-skills.”</p>
<p>There’s more to all this, but what I left unsaid (because it isn’t very relevant to students) is: if schools think AI literacy is so vital for their students’ future, then schools should create and require classes dedicated to teaching those skills, similar to a typing course. Otherwise, either they don’t believe AI is such a high priority or, worse, they believe it is but have no plan, other than punt the problem to shell-shocked teachers to deal with.</p>
<p>I’m not against AI in principle and was optimistic early on that we could find a clever way to make philosophy classes AI-friendly. Some courses may lend themselves to using AI, such as logic classes, but most philosophy classes appear resistant to that, at least without a major overhaul. Many attempts to integrate AI into a course seem gimmicky or gratuitous, which suggests they&#8217;re of questionable pedagogical value compared to time-tested assignments.</p>
<p>For instance, a popular idea is to get AI to do some philosophy, and then the student tries to play “gotcha” with it and identify its errors. Sure, this may have <em>some</em> value, but it’s hardly a substitution for writing a whole critical essay&#8212;not even close. Worse, the student can still game those assignments or cheat with AI, e.g., get a second AI to identify the first AI&#8217;s errors.</p>
<p>I do hope that AI and academia can co-exist peacefully, but it’s hard to see how right now. Other things would also need to be solved if we care about <em>ethical or responsible</em> AI use, such as AI’s massive energy costs, hallucinations, and many other things discussed in my article. So, in the absence of a general solution and in the meantime, a blanket ban on AI seems justifiable, if an instructor wants to adopt the policy. It’s also ok if some instructors want to experiment with AI and their students&#8212;that&#8217;s on them.</p>
<p>More nuanced approaches to AI use in the classroom are possible, e.g., &#8220;students may use AI for x but not for y&#8221;. But I didn’t choose those paths because I wanted to  avoid sending mixed messages and opening the door for abuse; a simple and clear policy seems better. Anyway, the blanket ban is just for the individual classroom; I’m not creating national policy here. If any student thinks AI is so important to their future that they should be learning how to use it, well, they can already do that for free at home or in other classes. No one is stopping them, and it ain’t rocket science, anyway.</p>
<p>Since the aim of my article is gentle persuasion, I wanted to start by giving credit where credit is due and acknowledge upfront that I’m <em>not</em> disputing AI’s utility. I’m happy to grant AI can be useful for students, even if I think the benefits are overblown, because there’s still a huge list of countervailing reasons against them using it. So many other articles on the subject come off as hostile, hyperbolic, alarmist, preachy, judgmental, scornful, and so on; even if such a tone is justified, it might not be helpful with persuasion and voluntary uptake.</p>
<p>And voluntary uptake may be critical in making the AI ban <em>self</em>-enforcing, as a best-case scenario. Or at least it’s worth a shot&#8212;desperate times call for desperate measures. For students who aren’t convinced, I’ve at least given a detailed defense, instead of imposing a dramatic policy without much explanation. The next-best outcome for student morale and course effectiveness is if they <em>understand</em> and go along with the policy, even if they’re unconvinced.</p>
<p>One obvious problem with my article is that it’s so long&#8212;I wish I had time to cut it in half, and maybe I’ll try later. (Yes, I gave the task to an AI as an experiment, and it failed terribly, at least to this author’s standards.) So, how do you get your students to read this? I’ll leave that for you to figure out, just as you’re already doing with the other articles, books, etc. in your own courses. For me, a spot-check quiz, an essay assignment around the article, and a running conversation (on Slack) over the length of the online course are part of the motivation, but there can also be other ways.</p>
<p>If you find <a href="https://emergingethics.substack.com/p/why-were-not-using-ai-in-this-course">the article</a> useful, feel free to use it in your courses however you like, even as a target article for students to pick apart or as the core of some AI assignment (but I’ll be sad if you do). Or if you think AI bans are silly, that’s fine, too&#8212;you do you. Whichever path you choose, good luck to all of us in the new academic year!</p><p>The post <a href="https://dailynous.com/2025/08/12/how-to-justify-an-ai-ban-in-your-classroom-guest-post/">How to Justify an AI Ban in Your Classroom (Guest Post)</a> first appeared on <a href="https://dailynous.com">Daily Nous</a>.</p>