<p>After months of development and refinement, I&rsquo;m excited to announce <strong>Ollama Buddy v1.0</strong> - an Emacs package that simply interfaces mainly to ollama, for local LLM usage, but can be integrated to the major online players. This project initially started as a simple integration with Ollama and since then has somewhat evolved into a more fully fully-featured AI Emacs assistant.  The main focus with this package is a front facing simplicity but hiding (hopefully) all the features you would expect from an AI chatbot - wait I hate that term, I mean, assistant :).  There is also the ability to craft a customizable menu system for different roles.</p>
<figure><img src="https://emacs.dyerdwelling.family/ox-hugo/20250424085731-emacs--Ollama-Buddy-0-9-35-Grok-Gemini-Integration-Enhanced-Sessions.jpg" width="100%">
</figure>

<p>I had a blast developing this package and next up is RAG!. I saw recently that a package called <code>vecdb</code> was introduced into the package ecosystem to help with the storage of vector embeddings, so as ollama can return embedding vectors for semantic search I thought I would combine my package, vecdb, also probably initially a PostgreSQL database with a pgvector extension and ollama into something that could ingest files directly from Emacs.  I think I have figured this out now, I just need to do it (when the baby is asleep, probably!)</p>
<h2 id="why-choose-ollama-buddy">Why Choose Ollama Buddy?</h2>
<p>I designed Ollama Buddy to be as simple as possible to set up, no backend configuration or complex setup required. This was achievable initially because I focused solely on Ollama integration, where models are automatically discoverable.</p>
<p>Since then, I&rsquo;ve expanded support to major online AI providers while maintaining that same simplicity through a modular architecture. The system now handles multiple providers without adding complexity to the user experience.</p>
<p>Another key feature is the customizable menu system, which integrates with role-based switching. You can create specialized AI menus for different contexts, like a coding-focused setup or a writing-optimized configuration and switch between them instantly. Everything is fully configurable to match your workflow.</p>
<h2 id="links">Links</h2>
<p>Here are some links:</p>
<p><a href="https://github.com/captainflasmr/ollama-buddy">https://github.com/captainflasmr/ollama-buddy</a>
<a href="https://melpa.org/#/ollama-buddy">https://melpa.org/#/ollama-buddy</a></p>
<p>I will outline the major features below, but I do have a manual available!</p>
<p><a href="https://github.com/captainflasmr/ollama-buddy/blob/main/docs/ollama-buddy.org">https://github.com/captainflasmr/ollama-buddy/blob/main/docs/ollama-buddy.org</a></p>
<h2 id="key-features">Key Features</h2>
<h3 id="multiple-ai-providers">Multiple AI Providers</h3>
<ul>
<li><strong>Local Models</strong>: Full support for Ollama with automatic model management</li>
<li><strong>Cloud Services</strong>: Integrated support for OpenAI (ChatGPT), Anthropic Claude, Google Gemini, and Grok</li>
<li><strong>Seamless Switching</strong>: Change between local and cloud models with a single command</li>
<li><strong>Unified Interface</strong>: Same commands work across all providers</li>
</ul>
<h3 id="role-based-workflows-build-your-own-ai-menu">Role-Based Workflows - build your own AI menu</h3>
<ul>
<li><strong>Preset Roles</strong>: Switch between different AI personalities (developer, writer, analyst, etc.)</li>
<li><strong>Custom Roles</strong>: Create specialized workflows with specific models and parameters</li>
<li><strong>Menu Customization</strong>: Each role can have its own set of commands and shortcuts</li>
</ul>
<h3 id="chat-interface">Chat Interface</h3>
<ul>
<li><strong>Org-mode Integration</strong>: Conversations rendered in structured org-mode format</li>
<li><strong>Real-time Streaming</strong>: Watch responses appear token by token</li>
<li><strong>Context Management</strong>: Visual context window monitoring with usage warnings</li>
<li><strong>History Tracking</strong>: Full conversation history with model-specific storage</li>
</ul>
<h3 id="file-handling">File Handling</h3>
<ul>
<li><strong>File Attachments</strong>: Attach documents directly to conversations for context-aware analysis</li>
<li><strong>Vision Support</strong>: Upload and analyse images with vision-capable models</li>
<li><strong>Dired Integration</strong>: Bulk attach files directly from Emacs file manager</li>
</ul>
<h3 id="prompt-management">Prompt Management</h3>
<ul>
<li><strong>System Prompts</strong>: Create and manage reusable system prompts for different use cases</li>
<li><strong>Fabric Integration</strong>: Auto-sync with Fabric patterns (200+ professional prompts)</li>
<li><strong>Awesome ChatGPT Prompts</strong>: Built-in access to the popular prompt collection</li>
<li><strong>User Prompts</strong>: Create and organize your own custom prompt library (which of course is org based)</li>
</ul>
<h3 id="session-management">Session Management</h3>
<ul>
<li><strong>Save &amp; Restore</strong>: Full session persistence including history, attachments, and settings</li>
<li><strong>Session Browser</strong>: Visual interface to manage multiple conversation sessions</li>
<li><strong>Auto-naming</strong>: Intelligent session naming based on conversation content</li>
</ul>
<h3 id="flexible-interface-options">Flexible Interface Options</h3>
<ul>
<li><strong>Two Interface Levels</strong>: Basic mode for beginners, advanced for power users</li>
<li><strong>Transient Menus</strong>: Magit-style discoverable command interface</li>
<li><strong>Custom Menus</strong>: Traditional text-based menu system</li>
<li><strong>Keyboard Shortcuts</strong>: Comprehensive keybinding system for efficiency, I&rsquo;m not sure there are any keys left!!</li>
</ul>
<h2 id="what-s-next">What&rsquo;s Next?</h2>
<p>Version 1.0 represents a stable, foundation, Ollama Buddy has been out there now for a few months with only a single github issue but development continues with:</p>
<ul>
<li>RAG integration using perhaps the new <code>vecdb</code> package, as mentioned above</li>
<li>Additional AI provider integrations (Perplexity maybe?, any suggestions?)</li>
<li>Auto-completion (not sure how doable this is with ollama, but I do have a prototype)</li>
</ul>
