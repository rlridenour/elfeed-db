Apple's new speech-to-text transcription APIs in iOS 26 and macOS Tahoe are delivering dramatically faster speeds compared to rival tools, including OpenAI's Whisper, based on beta testing conducted by <a href="https://www.macstories.net/stories/hands-on-how-apples-new-speech-apis-outpace-whisper-for-lightning-fast-transcription/"><em>MacStories</em>' John Voorhees</a>.  <br/>
<br/>
<img src="https://images.macrumors.com/article-new/2025/06/apple_record_transcribe_phone_calls.jpeg" alt="" width="1439" height="966" class="aligncenter size-full wp-image-1006652" /><div class="center-wrap"><em>Call recording and transcription in iOS 18.1</em></div><br/>
Apple uses its own native speech frameworks to power live transcription features in apps like Notes and Voice Memos, as well as phone call transcription in iOS 18.1. To improve efficiency in iOS 26 and macOS Tahoe, Apple has introduced a new <a href="https://developer.apple.com/videos/play/wwdc2025/277">SpeechAnalyzer class and SpeechTranscriber module</a> that deal with similar requests.<br/>
<br/>
According to Voorhees, the new models processed a 34-minute, 7GB video file in just 45 seconds using a command line tool called <a href="https://github.com/finnvoor/yap">Yap</a> (developed by Voorhees' son, Finn). That's a full 55% faster than <a href="https://goodsnooze.gumroad.com/l/macwhisper">MacWhisper</a>'s Large V3 Turbo model, which took 1 minute and 41 seconds for the same file.<br/>
<br/>
Other Whisper-based tools performed even slower, with <a href="https://apps.apple.com/us/app/ai-captions-for-videos-vidcap/id1620725834">VidCap</a> taking 1:55 and MacWhisper's Large V2 model requiring 3:55 to complete the same transcription task. Voorhees also reported no noticeable difference in transcription quality across models.<br/>
<br/>
The speed advantage comes from Apple's on-device processing approach, which avoids the network overhead that typically slows cloud-based transcription services. <br/>
<br/>
While the time difference might seem modest for individual files, Voorhees notes that the performance gain increases exponentially when processing multiple videos or longer content. For anyone generating subtitles or transcribing lectures regularly, the efficiency boost could save them hours.<br/>
<br/>
The Speech framework components are available across iPhone, iPad, Mac, and Vision Pro platforms in the current beta releases. Voorhees expects Apple's transcription technology to eventually replace <a href="https://platform.openai.com/docs/models/whisper-1">Whisper</a> as the go-to solution for Mac transcription apps.<div class="linkback">Related Roundups: <a href="https://www.macrumors.com/roundup/ios-26/">iOS 26</a>, <a href="https://www.macrumors.com/roundup/ipados-26/">iPadOS 26</a>, <a href="https://www.macrumors.com/roundup/macos-26/">macOS Tahoe 26</a></div><div class="linkback">Related Forums: <a href="https://forums.macrumors.com/forums/ios-26.248">iOS 26</a>, <a href="https://forums.macrumors.com/forums/macos-tahoe.250">macOS Tahoe</a></div><br/>This article, &quot;<a href="https://www.macrumors.com/2025/06/18/apple-transcription-api-faster-than-whisper/">Apple&#039;s New Transcription APIs Blow Past Whisper in Speed Tests</a>&quot; first appeared on <a href="https://www.macrumors.com">MacRumors.com</a><br/><br/><a href="https://forums.macrumors.com/threads/apples-new-transcription-apis-blow-past-whisper-in-speed-tests.2459228/">Discuss this article</a> in our forums<br/><br/>