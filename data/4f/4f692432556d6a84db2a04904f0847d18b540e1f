<p>A philosopher noticed something off about the paper he was refereeing for a journal.<span id="more-55436"></span></p>
<p>In the following guest post, <a href="http://stirlingbus.com/jso/" target="_blank" rel="noopener">Jakob Ohlhorst</a> (RWTH Aachen University) shares his experience and raises some questions about how to deal with the problem he encountered.</p>
<hr />
<h2><img loading="lazy" decoding="async" class=" wp-image-55442 aligncenter" src="https://dailynous.com/wp-content/uploads/2025/10/chatgpt-on-using-chatgpt.png" alt="" width="788" height="400" srcset="https://dailynous.com/wp-content/uploads/2025/10/chatgpt-on-using-chatgpt.png 1900w, https://dailynous.com/wp-content/uploads/2025/10/chatgpt-on-using-chatgpt-300x152.png 300w, https://dailynous.com/wp-content/uploads/2025/10/chatgpt-on-using-chatgpt-1024x520.png 1024w, https://dailynous.com/wp-content/uploads/2025/10/chatgpt-on-using-chatgpt-768x390.png 768w, https://dailynous.com/wp-content/uploads/2025/10/chatgpt-on-using-chatgpt-1536x779.png 1536w, https://dailynous.com/wp-content/uploads/2025/10/chatgpt-on-using-chatgpt-400x203.png 400w" sizes="auto, (max-width: 788px) 100vw, 788px" /></h2>
<h2 style="text-align: center;">Reviewing an LLM-written paper<br />
<strong><em>by Jakob Ohlhorst</em></strong></h2>
<p>It was bound to happen. I reviewed my first apparently LLM-generated paper.</p>
<p>I enjoy reviewing, helping the authors shape, sharpen and situate their papers. This wasn’t much fun though. I accepted the review by accident, clicking the wrong link; but the title and abstract were interesting enough, connecting different topics I am interested in. So I committed to it anyway.</p>
<p>Reviewing this text was an interesting experience. I started out curious about how the paper would fulfil the promises made in title and abstract (I’ll not go into any identifying detail, as I am concerned with the general issue, than the specific article). The introduction was fairly broad, the vagueness of some concepts and ideas concerned me somewhat, but I assumed that this was just giving the gist, playing fast and loose. The paper was short after all, I’d get to the substance soon enough.</p>
<p>The first section, introducing a special kind of coherentism was more or less right but underwhelming. Significant characteristics were missing. As a result the paper simply offered an explanation of coherentism. The second section was worse, however, as it was applying this coherentism to a specialised domain without saying exactly what was supposed to be coherent or how. Instead, the text pointed to general structural parallels between coherentism and the field.</p>
<p>By the third section, four pages in, I became aware of the prose. It was good English, but vague with a strange rhythm, exhausting to read. It felt like wading through cotton candy: little resistance, no real substance. Even the real-world phenomenon that coherentism was supposed to be applied to in section three remained underspecified and nebulous.</p>
<p>I pasted the most offending passage, the explanation of coherentism, into an online LLM-detector. The result was (65%) positive. My first charitable thought was, &#8220;maybe it’s just this summary which is laying the ground while the rest is more solid.&#8221; I checked the references. Those were hallucinated. I was quite angry.</p>
<p>For me, this raises a few questions:</p>
<ul>
<li>Is this one of the first cases of this in philosophy (and so the problem will only worsen); or has this already become widespread?</li>
<li>Are editorial processes already flagging this pre-review, and I caught one that slipped through? Ought checking for hallucinated references be among the minimal tasks the editorial team completes before sending manuscripts to referees?</li>
<li>How much can we rely on LLM-detectors?</li>
</ul>
<p>What makes me optimistic: I was able to recognize the problem soon enough. But it was still a waste of time that I could have spent reviewing a real paper.</p>
<p>I sympathize with non-native authors who face considerable hurdles writing in academic English and who therefore consider relying on the help of LLMs. However, submitting completely LLM-generated text is unacceptable in terms of academic integrity, and not even a good idea prudentially, as the style is noticeable and not very agreeable. I would suggest using LLMs very sparingly, as even raising the suspicion of LLM-use in a referee will do a paper no good.</p><p>The post <a href="https://dailynous.com/2025/10/28/reviewing-an-llm-written-paper-guest-post/">Reviewing an LLM-written paper (guest post)</a> first appeared on <a href="https://dailynous.com">Daily Nous</a>.</p>