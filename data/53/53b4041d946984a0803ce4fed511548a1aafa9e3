<p>In  Richard Gabriel's essay &ldquo;Worse
  is Better &rdquo;,  Gabriel contrasts
  the &ldquo;MIT approach&rdquo; of designing for correctness and
  completeness with the &ldquo;New Jersey approach&rdquo; of designing
  for simplicity of implementation.  He argues that the MIT
  approach, which is more principled, is likely to be overtaken by the
  New Jersey approach, which is easier to reproduce.  While writing
  the prompt for the Advent of Code problems, I noticed that my prompt
  was reminiscent of Gabriel's characterizations.  I decided to get
  the LLM to compare the two approaches by running it on each type of
  prompt and seeing how the output differed.</p>

<h2>Prompts</h2>
<p>The salient part of the MIT prompt is</p>

<p>As an <strong>Elite Common Lisp Developer</strong>, your unwavering and paramount mission is to design and meticulously craft Common Lisp programs that are not only <strong>correct</strong>, but also <strong>simple</strong>, <strong>efficient</strong>, and <strong>robust</strong>.  Your programs are not mere instructions; they are masterpieces of clarity and precision, firmly grounded in these foundational, <strong>non-negotiable</strong> principles:</p>

<ul><li>  <strong>Correctness</strong> Your program <strong>must</strong> be correct in all observable aspects.  Incorrectness is simply not allowed.</li>
<li>  <strong>Consistency</strong> Your program <strong>must</strong> be consistent.  Consistency is as important as correctness.  Simplicity may be sacrificed for consistency and correctness.</li>
<li>  <strong>Simplicity</strong> Your program <strong>must</strong> be as simple as possible, but no simpler.  It is more important for the interface to be simple than the implementation.  Simplicity is not allowed to overly reduce completeness.</li>
<li>  <strong>Completeness</strong> Your program <strong>must</strong> cover as many important situations as is practical.  All reasonably expected situations must be handled.</li>
</ul>

<p>The salient part of the New Jersey prompt is </p>
<p>As an <strong>Expert Common Lisp Developer</strong>, your primary and overriding
  objective is to create Common Lisp programs that are <strong>simple</strong>.  While other
  qualities such as <strong>consistency</strong>, <strong>completeness</strong>, and
  <strong>correctness</strong> are important, they are secondary to simplicity.
  Your programs should be designed with the following prioritized
  principles in mind:</p>

<ul>
<li>    <strong>Simplicity</strong> Your program <strong>must</strong> be simple, both in interface and implementation.  It is more important for the implementation to be simple than the interface.  Simplicity is the most important consideration in the design.</li>
<li>  <strong>Correctness</strong> Your program <strong>must</strong> be correct in all observable aspects.  It is slightly better that your program be simple than correct.</li>
<li>  <strong>Consistency</strong> Your program <strong>must not</strong> be overly inconsistent.  Consistency can be sacrificed for simplicity in some cases, but it is better to drop those parts of the design that deal with less common circumstances than to introduce either implementational complexity or inconsistency.</li>
<li>  <strong>Completeness</strong> Your program <strong>must</strong> cover as many important situations as is practical. All reasonably expected cases should be covered. Completeness can be sacrificed in favor of any other quality. In fact, completeness <strong>must</strong> be sacrificed whenever implementation simplicity is jeopardized. Consistency can be sacrificed to achieve completeness if simplicity is retained; especially worthless is consistency of interface.</li></ul>

<p>Both prompts had additional instructions about how to find the
  input and where to write the output.</p>

<h2>Results</h2>

<p>I had Gemini analyze the solution pairs to the Advent of Code
  problems.  In almost every case, Gemini preferred the MIT approach
  to the New Jersey approach.  Here is an example analysis of day
  10:</p>

<p>Excellent. I have the contents of both files. I will now proceed with a detailed analysis and comparison, as requested.</p>

<h3>Analysis of <code>day10_right_thing_solution.lisp</code></h3>

<p>This solution presents a very clean, structured, and pragmatic approach. It reads as a piece of code written by a developer who values clarity and standard algorithmic patterns.</p>

<p><strong>Structure:</strong></p>
<ul><li>
   The code is well-organized into distinct functions, each with a single, clear purpose: <code>parse-input</code>, <code>find-trailheads</code>, <code>get-neighbors</code>, <code>calculate-score</code> (for Part 1), <code>calculate-rating</code> (for Part 2), and a main <code>solve</code> function to orchestrate the process.</li>
<li>   This separation of concerns makes the code easy to read, test, and debug. The main <code>solve</code> function provides a high-level summary of the program's execution flow.</li></ul>

<p><strong>Algorithms &amp; Style:</strong></p>
<ul><li>
<strong>Part 1 (<code>calculate-score</code>):</strong> This function uses a classic <strong>iterative Breadth-First Search (BFS)</strong>. The use of a queue (<code>q</code>) and a <code>visited</code> hash table is a textbook implementation for graph traversal. This approach is highly efficient and guarantees finding the shortest path in terms of steps, though that is not a requirement here. It is robust and not susceptible to stack depth limits.</li>
<li>   <strong>Part 2 (<code>calculate-rating</code>):</strong> This function employs a <strong>bottom-up dynamic programming</strong> strategy. It builds a <code>path-counts</code> table, iterating through the heights from 1 to 9. For each cell, it calculates the number of paths to it by summing the paths from its valid, lower neighbors. This is a very efficient and elegant method that avoids the combinatorial explosion of a naive search.</li>
<li>   <strong>Lisp Idioms:</strong> The code uses common and readable Lisp constructs like <code>loop</code>, <code>dotimes</code>, <code>destructuring-bind</code>, and <code>let*</code>. The use of hash tables for <code>visited</code> sets is appropriate and performant.</li></ul>

<p><strong>Strengths:</strong></p>
<ul><li><strong>Clarity and Readability:</strong> The code is exceptionally clear. Function names are descriptive, and the logic is straightforward and easy to follow.</li>
<li><strong>Robustness:</strong> The iterative algorithms are safe from stack overflow errors, making the solution suitable for arbitrarily large inputs.</li>
<li><strong>Efficiency:</strong> Both the BFS and the bottom-up DP are highly efficient algorithms for their respective problems.</li></ul>

<p><strong>Weaknesses:</strong></p>
<ul><li><strong>Minor Environmental Dependency:</strong> It relies on
    a placeholder <code>readFileLines</code> function, making it slightly less
    portable out-of-the-box compared to a solution using a standard
    library like UIOP.</li></ul>

<h3>Analysis of <code>day10_new_jersey_solution.lisp</code></h3>

<p>This solution uses a recursive approach, which can be very elegant but also carries certain trade-offs. It feels more like a direct translation of a mathematical recurrence relation.</p>

<strong>Structure:</strong>
<ul>
<li>   The overall structure is similar, with parsing and solving functions. However, the core algorithmic logic is encapsulated within local functions defined by <code>labels</code>.</li>
<li>   This makes the solver functions more self-contained but also increases their cognitive complexity, as the main logic is nested one level deeper.</li></ul>

<strong>Algorithms & Style:</strong>
<ul>
<li>   <strong>Part 1 (<code>solve-part1</code>):</strong> This function uses a <strong>recursive Depth-First Search (DFS) with memoization</strong>. The <code>find-reachable-nines</code> local function explores paths recursively. The <code>memo</code> hash table is crucial to prevent re-computation and avoid infinite loops, effectively turning the search into a dynamic programming solution on a graph. The use of <code>union</code> to merge results from recursive calls can be inefficient, as it requires traversing lists.</li>
<li>   <strong>Part 2 (<code>solve-part2</code>):</strong> This also uses a <strong>recursive DFS with memoization (top-down dynamic programming)</strong>. The <code>count-paths</code> function is a classic example of this pattern. It computes the number of paths from a given cell and stores the result in the <code>memo</code> table before returning it.</li>
<li>   <strong>Lisp Idioms:</strong> The use of <code>labels</code> for recursion is a very common and powerful Lisp idiom. The use of <code>cons</code> cells for coordinates is also common, though perhaps slightly less explicit than a <code>list</code>. It correctly uses <code>uiop:read-file-lines</code> for better portability.</li></ul>

<strong>Strengths:</strong>
<ul><li>   <strong>Elegance of Recursion:</strong> For those comfortable with recursion, the code can be seen as a very direct and elegant expression of the problem's structure.</li>
<li>   <strong>Portability:</strong> The use of <code>uiop</code> for file reading is a good practice.</li></ul>

<strong>Weaknesses:</strong>
<ul><li>   <strong>Stack Overflow Risk:</strong> The primary weakness is its reliance on deep recursion. For a sufficiently large or complex input grid, this solution could exceed the call stack limit and crash, whereas an iterative solution would not.</li>
<li>   <strong>Lower Readability:</strong> The combination of recursion, memoization, and nested functions can make the logic harder to trace and debug compared to the straightforward iterative loops in the first solution.</li>
<li>   <strong>Potential Inefficiency:</strong> The use of <code>union</code> in Part 1 is likely less performant than the hash-table approach used in the first solution for tracking unique reachable nodes.</li></ul>

### Comparison and Final Recommendation

<table>
  <tr>
    <th>Feature</th>
    <th><code>right_thing_solution</code></th>
    <th><code>new_jersey_solution</code></th>
  </tr>
  <tr>
    <td><strong>Paradigm</strong></td>
    <td>Iterative (BFS, Bottom-up DP)</td>
    <td>Recursive (DFS with Memoization)</td>
  </tr>
  <tr>
    <td><strong>Robustness</strong></td>
    <td>Superior. Immune to stack overflow.</td>
    <td>Weaker. Vulnerable to stack overflow.</td>
  </tr>
  <tr>
    <td><strong>Clarity</strong></td>
    <td>Superior. Clear, flat structure. Standard algorithms.</td>
    <td>Good, but more complex. Nested logic can be harder to follow.</td>
    </tr>
  <tr>
    <td><strong>Performance</strong></td>
    <td>Excellent. Efficient, standard algorithms.</td>
    <td>Good, but recursion overhead and <code>union</code> may be slower.</td>
    </tr>
  <tr>
    <td><strong>Style</strong></td>
    <td>Pragmatic, clear, maintainable.</td>
    <td>Elegant, concise, mathematical.</td>
  </tr>
  </table>



<strong>Recommendation</strong>

<p>While both files represent valid and functional solutions to the
  problem, <strong>I unequivocally
    recommend <code>day10_right_thing_solution.lisp</code> as the better overall solution.</strong></p>

<p><strong>Justification:</strong></p>

<ol>
<li>  <strong>Robustness is Paramount:</strong> The most critical advantage of the "Right Thing" solution is its immunity to stack overflow errors. This makes it fundamentally more reliable and suitable for general-purpose use where input constraints may not be known. In a professional software engineering context, this is a decisive factor.</li>
<li>  <strong>Clarity Enhances Maintainability:</strong> The code in the "Right Thing" solution is significantly easier to read, understand, and maintain. A developer can grasp the BFS and bottom-up DP algorithms quickly, making debugging and future modifications simpler. The recursive nature of the "New Jersey" solution, while elegant, requires more mental effort to trace.</li>
<li>  <strong>Efficiency and Predictability:</strong> The iterative approach offers more predictable performance. The BFS algorithm and the systematic table-filling of the DP solution have well-understood and excellent time complexities, free from the overhead of function calls inherent in recursion.</li></ol>

<p>In conclusion, the "New Jersey" solution is a fine example of a recursive, top-down DP approach. However, the <strong>"Right Thing" solution embodies a superior engineering strategy</strong>, prioritizing robustness, clarity, and maintainability, which are the hallmarks of high-quality, professional-grade code. It is the solution I would write and the one I would want to inherit in a team setting.</p>