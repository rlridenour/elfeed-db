<p id="p1">Speaking of the new Mac Studio and <a href="https://www.macstories.net/linked/is-apple-shipping-the-best-ai-computers/" rel="noopener noreferrer">Apple making the best computers for AI</a>: this is <a href="https://creativestrategies.com/mac-studio-m3-ultra-ai-workstation-review/" rel="noopener noreferrer">a terrific overview by Max Weinbach</a> about the new M3 Ultra chip and its real-world performance with various on-device LLMs:</p>
<blockquote id="blockquote2"><p>
  The Mac I&rsquo;ve been using for the past few days is the Mac Studio with M3 Ultra SoC, 32-core CPU, 80-core GPU, 256GB Unified Memory (192GB usable for VRAM), and 4TB SSD. It&rsquo;s the fastest computer I have. It is faster in my workflows for even AI than my gaming PC (which will be used for comparisons below; it has an Intel i9&nbsp;13900K, RTX 5090, 64GB of DDR5, and a 2TB NVMe SSD).
</p></blockquote>
<p id="p3">It&rsquo;s a very technical read, but the comparison between the M3 Ultra and a vanilla (non-optimized) RTX 5090 is mind-blogging to me. According to Weinbach, it all comes down to Apple&rsquo;s MLX framework:</p>
<blockquote id="blockquote4"><p>
  I&rsquo;ll keep it brief; the LLM performance is essentially as good as you&rsquo;ll get for the majority of models. You&rsquo;ll be able to run better models faster with larger context windows on a Mac Studio or any Mac with Unified Memory than essentially any PC on the market. This is simply the inherent benefit of not only Apple Silicon but Apple&rsquo;s MLX framework (the reason we can efficiently run the models without preloading KV Cache into memory, as well as generate tokens faster as context windows grow).
</p></blockquote>
<p id="p5">In case you&rsquo;re not familiar, <a href="https://opensource.apple.com/projects/mlx/" rel="noopener noreferrer">MLX</a> is Apple&rsquo;s <a href="https://github.com/ml-explore/mlx" rel="noopener noreferrer">open-source</a> framework that &ndash; I&rsquo;m simplifying &ndash; optimizes training and serving models on Apple Silicon&rsquo;s unified memory architecture. It is a wonderful project with over 1,600&nbsp;<a href="https://huggingface.co/mlx-community" rel="noopener noreferrer">community models</a> available for download.</p>
<p id="p6">As Weinbach concludes:</p>
<blockquote id="blockquote7"><p>
  I see one of the best combos any developer can do as: M3 Ultra Mac Studio with an Nvidia 8xH100 rented rack. Hopper and Blackwell are outstanding for servers, M3 Ultra is outstanding for your desk. Different machines for a different use, while it&rsquo;s fun to compare these for sport, that&rsquo;s not the reality.&#8288;&#8288;</p>
<p>  <strong>There really is no competition for an AI workstation today. The reality is, the only option is a Mac Studio.</strong>
</p></blockquote>
<p id="p8">Don&rsquo;t miss <a href="https://creativestrategies.com/mac-studio-m3-ultra-ai-workstation-review/" rel="noopener noreferrer">the benchmarks in the story</a>.</p>
<p>â†’ Source: <a href='https://creativestrategies.com/mac-studio-m3-ultra-ai-workstation-review/' target='_blank'>creativestrategies.com</a></p>