<p>[Equations in this post may not look right (or appear at all) in your RSS reader. Go to <a href="https://leancrew.com/all-this/2025/11/variance-of-a-sum/">the original article</a> to see them rendered properly.]</p>
  <hr />
  <p>Earlier this week, John D. Cook wrote a post about <a href="https://www.johndcook.com/blog/2025/11/12/minimum-variance/">minimizing the variance of a sum of random variables</a>. The sum he looked at was this:</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi><mo>=</mo><mi>t</mi><mspace width="0.167em"></mspace><mi>X</mi><mo>+</mo><mo form="prefix" stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>Y</mi></math>
<p>where <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> are independent random variables, and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> is a deterministic value. The proportion of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math> that comes from <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> is <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> and the proportion that comes from <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> is <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo>−</mo><mi>t</mi></mrow></math>. The goal is to choose <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> to minimize the variance of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math>. As Cook says, this is weighting the sum to minimize its variance.</p>
<p>The result he gets is</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mo>=</mo><mfrac><mrow><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>Y</mi><mo form="postfix" stretchy="false">)</mo></mrow><mrow><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>X</mi><mo form="postfix" stretchy="false">)</mo><mo>+</mo><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>Y</mi><mo form="postfix" stretchy="false">)</mo></mrow></mfrac></math>
<p>and one of the consequences of this is that if <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> have equal variances, the <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> that minimizes the variance of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math> is <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow></math>.</p>
<p>You might think that if the variances are equal, it shouldn’t matter what proportions you use for the two random variables, but it does. That’s due in no small part to the independence of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math>, which is part of the problem’s setup.</p>
<p>A natural question to ask, then, is what happens if <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> <em>aren’t</em> independent. That’s what we’ll look into here.</p>
<hr/>
<p>First, a little review. The <a href="https://en.wikipedia.org/wiki/Variance">variance</a> of a random variable, <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math>, is defined as</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>X</mi><mo form="postfix" stretchy="false">)</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mi>X</mi></msub><msup><mo form="postfix" stretchy="false">)</mo><mn>2</mn></msup><msub><mi>f</mi><mi>X</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>x</mi></math>
<p>where <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>μ</mi><mi>X</mi></msub></math> is the mean value of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>f</mi><mi>X</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo form="postfix" stretchy="false">)</mo></mrow></math> is its <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a> (PDF). The most familiar PDF is the bell-shaped curve of the <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a>.</p>
<p>The mean value is defined like this:</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>μ</mi><mi>X</mi></msub><mo>=</mo><msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mi>x</mi><mspace width="0.167em"></mspace><msub><mi>f</mi><mi>X</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>x</mi></math>
<p>People often like to work with the <a href="https://en.wikipedia.org/wiki/Standard_deviation">standard deviation</a> <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>σ</mi><mi>X</mi></msub></math> instead of the variance. The relationship is</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>X</mi><mo form="postfix" stretchy="false">)</mo><mo>=</mo><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup></math>
<p>Now let’s consider two random variables, <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math>. They have a joint PDF, <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>f</mi><mrow><mi>X</mi><mi>Y</mi></mrow></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo form="postfix" stretchy="false">)</mo></mrow></math>. The <a href="https://en.wikipedia.org/wiki/Covariance">covariance</a> of the two is defined like this:</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo form="postfix" stretchy="false">)</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mspace width="0.167em"></mspace><msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mi>X</mi></msub><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mo form="prefix" stretchy="false">(</mo><mi>y</mi><mo>−</mo><msub><mi>μ</mi><mi>Y</mi></msub><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><msub><mi>f</mi><mrow><mi>X</mi><mi>Y</mi></mrow></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>x</mi><mspace width="0.167em"></mspace><mi>d</mi><mi>y</mi></math>
<p>It’s common to express the covariance in terms of the standard deviations and the correlation coefficient, <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ρ</mi></math>:</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo form="postfix" stretchy="false">)</mo><mo>=</mo><mi>ρ</mi><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>X</mi></msub><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>Y</mi></msub></math>
<p>If we were going to deal with more random variables, I’d explicitly include the variables as subscripts to <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ρ</mi></math>, but there’s no need to in the two-variable situation.</p>
<p>The correlation coefficient is a pure number and is always in this range:</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>−</mi><mn>1</mn><mo>≤</mo><mi>ρ</mi><mo>≤</mo><mn>1</mn></math>
<p>A positive value of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ρ</mi></math> means that the two variables tend to be above or below their respective mean values at the same time. A negative value of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ρ</mi></math> means that when one variable is above its mean, the other tends to be below its mean, and vice versa.</p>
<p>If <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> are independent, their joint PDF can be expressed as the product of two individual PDFs:</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>f</mi><mrow><mi>X</mi><mi>Y</mi></mrow></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo form="postfix" stretchy="false">)</mo><mo>=</mo><msub><mi>f</mi><mi>X</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><msub><mi>f</mi><mi>Y</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>y</mi><mo form="postfix" stretchy="false">)</mo></math>
<p>which means</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML">
<mtable style="math-style: normal">
<mtr>
<mtd>
<mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi></mrow><mo form="prefix" stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo form="postfix" stretchy="false">)</mo>
</mtd>
<mtd><mo>=</mo></mtd>
<mtd>
<msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mspace width="0.167em"></mspace><msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mi>X</mi></msub><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mo form="prefix" stretchy="false">(</mo><mi>y</mi><mo>−</mo><msub><mi>μ</mi><mi>Y</mi></msub><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><msub><mi>f</mi><mi>X</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><msub><mi>f</mi><mi>Y</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>y</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>x</mi><mspace width="0.167em"></mspace><mi>d</mi><mi>y</mi>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd><mo>=</mo></mtd>
<mtd>
<msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>μ</mi><mi>X</mi></msub><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><msub><mi>f</mi><mi>X</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>x</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>x</mi><mspace width="0.167em"></mspace><msubsup><mo>∫</mo><mrow><mi>−</mi><mi>∞</mi></mrow><mi>∞</mi></msubsup><mo form="prefix" stretchy="false">(</mo><mi>y</mi><mo>−</mo><msub><mi>μ</mi><mi>Y</mi></msub><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><msub><mi>f</mi><mi>Y</mi></msub><mo form="prefix" stretchy="false">(</mo><mi>y</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>d</mi><mi>y</mi>
</mtd>
</mtr>
<mtr>
<mtd> </mtd>
<mtd><mo>=</mo></mtd>
<mtd style="text-align: left"><mspace height="1.5em"></mspace><mn>0</mn></mtd>
</mtr>
</mtable>
</math>
<p>because of the definition of the mean given above. Cook took advantage of this in his analysis to simplify his equations. We won’t be doing that.</p>
<hr/>
<p>Going back to our definition of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math>,</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi><mo>=</mo><mi>t</mi><mspace width="0.167em"></mspace><mi>X</mi><mo>+</mo><mo form="prefix" stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>Y</mi></math>
<p>the variance of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math> is</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>σ</mi><mi>Z</mi><mn>2</mn></msubsup><mo>=</mo><msup><mi>t</mi><mn>2</mn></msup><mspace width="0.167em"></mspace><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup><mo>+</mo><mn>2</mn><mspace width="0.167em"></mspace><mi>t</mi><mspace width="0.167em"></mspace><mo form="prefix" stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><mi>ρ</mi><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>X</mi></msub><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>Y</mi></msub><mo>+</mo><mo form="prefix" stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><msup><mo form="postfix" stretchy="false">)</mo><mn>2</mn></msup><msubsup><mi>σ</mi><mi>Y</mi><mn>2</mn></msubsup></math>
<p>To get the value of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> that minimizes the variance, we take the derivative with respect to <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> and set that equal to zero. This leads to</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mo>=</mo><mfrac><mrow><msubsup><mi>σ</mi><mi>Y</mi><mn>2</mn></msubsup><mo>−</mo><mi>ρ</mi><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>X</mi></msub><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>Y</mi></msub></mrow><mrow><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup><mo>−</mo><mn>2</mn><mspace width="0.167em"></mspace><mi>ρ</mi><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>X</mi></msub><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>Y</mi></msub><mo>+</mo><msubsup><mi>σ</mi><mi>Y</mi><mn>2</mn></msubsup></mrow></mfrac></math>
<p>This reduces to Cook’s equation when <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ρ</mi><mo>=</mo><mn>0</mn></math>, which is what we’d expect.</p>
<p>At this value of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math>, the variance of the sum is</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>σ</mi><mi>Z</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><mo form="prefix" stretchy="true">(</mo><mn>1</mn><mo>−</mo><msup><mi>ρ</mi><mn>2</mn></msup><mo form="postfix" stretchy="true">)</mo><mspace width="0.167em"></mspace><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup><mspace width="0.167em"></mspace><msubsup><mi>σ</mi><mi>Y</mi><mn>2</mn></msubsup></mrow><mrow><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup><mo>−</mo><mn>2</mn><mspace width="0.167em"></mspace><mi>ρ</mi><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>X</mi></msub><mspace width="0.167em"></mspace><msub><mi>σ</mi><mi>Y</mi></msub><mo>+</mo><msubsup><mi>σ</mi><mi>Y</mi><mn>2</mn></msubsup></mrow></mfrac></math>
<p>Considering now the situation where <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>σ</mi><mi>Y</mi></msub><mo>=</mo><msub><mi>σ</mi><mi>X</mi></msub></mrow></math>, the value of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> that minimizes the variance is</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mo>=</mo><mfrac><mrow><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup><mo>−</mo><mi>ρ</mi><mspace width="0.167em"></mspace><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup></mrow><mrow><mn>2</mn><mspace width="0.167em"></mspace><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup><mo>−</mo><mn>2</mn><mspace width="0.167em"></mspace><mi>ρ</mi><mspace width="0.167em"></mspace><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></math>
<p>which is the same result as before. In other words, when the variances of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> are equal, the variance of their sum is minimized by having equal amounts of both, regardless of their correlation. I don’t know about you, but I wasn’t expecting that.</p>
<p>Just because the minimizing value of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> doesn’t depend on the correlation coefficient, that doesn’t mean the variance itself doesn’t. The minimum variance of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math> when <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>σ</mi><mi>Y</mi></msub><mo>=</mo><msub><mi>σ</mi><mi>X</mi></msub></mrow></math> is</p>
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>σ</mi><mi>Z</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mspace width="0.167em"></mspace><mo form="prefix" stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>ρ</mi><mo form="postfix" stretchy="false">)</mo><mspace width="0.167em"></mspace><msubsup><mi>σ</mi><mi>X</mi><mn>2</mn></msubsup></math>
<p>A pretty simple result and one that I <em>did</em> expect. When <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> are positively correlated, their extremes tend to reinforce each other and the variance of <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math> goes up. When <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Y</mi></math> are negatively correlated, their extremes tend to balance out, and <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math> stays closer to its mean value.</p>
  
