<p>John Voorhees of MacStories took Apple’s new Speech framework, available to all developers, for a spin in the macOS 26 beta and <a href="https://www.macstories.net/stories/hands-on-how-apples-new-speech-apis-outpace-whisper-for-lightning-fast-transcription/">got great results in making audio transcripts</a>:</p>
<blockquote><p>
  It’s still early days for these technologies, but I’m here to tell you that their speed alone is a game changer for anyone who uses voice transcription to create text from lectures, podcasts, YouTube videos, and more. That’s something I do multiple times every week for <a href="https://appstories.net/">AppStories</a>, <a href="https://www.macstories.net/npc/">NPC</a>, and <a href="https://www.macstories.net/unwind/">Unwind</a>, generating transcripts that I upload to YouTube because the site’s built-in transcription isn’t very good.
</p></blockquote>
<p>I’ve been using OpenAI’s open-source Whisper system (mosty <a href="https://github.com/ggml-org/whisper.cpp">whisper.cpp</a>) for a couple of years, and while it seems to be more accurate than Apple’s model, it’s also half the speed of the large-v3-turbo model I’ve defaulted to lately.</p>
<p>It’s great to see that Apple is in this game, and even better, that it’s handing the power of this model to app developers so they can built speech-to-text transcription features directly into their apps.</p>
<p><a href="https://www.macstories.net/stories/hands-on-how-apples-new-speech-apis-outpace-whisper-for-lightning-fast-transcription/">Go to the linked site</a>.</p><p><a href="https://sixcolors.com/link/2025/06/apples-built-in-transcriber-blows-away-whisper/">Read on Six Colors</a>.</p>