<p>On Tuesday, Apple announced accessibility feature updates for users with blindness, hearing loss, cognitive delays, and motor disabilities, along with a new way for developers to demonstrate the accessibility of their apps.</p>
<p>The company typically marks <a href="https://accessibility.day">Global Accessibility Awareness Day</a> (May 15) with a preview of features that will be available on all platforms as part of the fall OS updates. The list of features slated for “later this year” is especially comprehensive, encompassing a range of options for most accessibility categories.</p>

<h2>Accessibility nutrition labels</h2>
<figure><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/sixcolors.com/wp-content/uploads/2025/05/accessibility-wide-6c.jpg?ssl=1" alt="" data-image-w="" data-image-h="" class=" jetpack-broken-image"><figcaption>The App Store will now nutrition label style entries for accessibility.</figcaption></figure>
<p>App Store pages will soon include fields for developers to indicate which accessibility features their app supports, along with links to more detailed information. Examples include: VoiceOver, Voice Control, dark appearance, larger text, and more. Media app pages can indicate if the app supports audio description and/or captioning.</p>
<p>It’s safe to say that accessibility users have long requested a way to determine accessibility before downloading. For developers, the labels provide a means to differentiate between apps that prioritize accessibility and those that do not. Apple intends to use the labels for its apps. The company will highlight the labels at WWDC, showing developers how to use them on their App Store pages.</p>
<h2>Vision accessibility</h2>
<figure><img data-recalc-dims="1" height="907" width="1360" decoding="async" src="https://i0.wp.com/sixcolors.com/wp-content/uploads/2025/05/Apple-accessibility-features-Magnifier-on-Mac.png?resize=1360%2C907&#038;ssl=1" alt="Magnifier for Mac" data-image-w="" data-image-h="" class=" jetpack-broken-image"><figcaption>Apple is bringing its iOS Magnifier app to the Mac.</figcaption></figure>
<p>Magnifier is coming to the Mac for the first time, allowing low-vision users to enlarge their view of distant materials, such as a classroom screen or whiteboard, by connecting an iPhone or other camera to their computer. The feature also works in conjunction with Continuity Camera and Desk View to enlarge documents or other close-up materials. Magnifier for Mac will also enable users to zoom in on and capture text that the camera sees.</p>
<p>The Magnifier for iPhone has recently been adding features that make it a useful alternative to a <a href="https://www.afb.org/blindness-and-low-vision/using-technology/assistive-technology-products/video-magnifiers">CCTV device</a> — an expensive piece of assistive technology gear that many people with low vision use to read and perform close-up work. The Mac version of Magnifier will make that convergence far more explicit.</p>
<p>Vision Pro will get new low-vision features, including the ability to zoom using the live camera. visionOS will also add an API that supports access to the camera by approved visual interpretation services, such as <a href="https://www.bemyeyes.com">Be My Eyes</a>, which enable agents to view what a user’s camera is capturing and provide assistance and descriptions of what they see.</p>
<p>Braille Access is a new way for Braille users to launch apps and take notes using Braille. It supports Braille Grade 3 and Nemeth Code for equations.</p>
<h2>Cognitive access</h2>
<figure><img data-recalc-dims="1" height="971" width="1360" decoding="async" src="https://i0.wp.com/sixcolors.com/wp-content/uploads/2025/05/Apple-accessibility-features-Accessibility-Reader.png?resize=1360%2C971&#038;ssl=1" alt="Accessibility Reader" data-image-w="" data-image-h="" class=" jetpack-broken-image"><figcaption>Accessibility Reader is a new feature that can make it easier for those with cognitive impairments to read onscreen text.</figcaption></figure>
<p>The Accessibility Reader will enable individuals with cognitive impairments, or those who work with them, to adjust the appearance of text to make it easier to process. That could mean a “friendlier font”, different spacing, or more (or less) vivid colors, based on an individual’s needs. Text can also be captured from the real world and brought into Accessibility Reader.</p>
<h2>Hearing</h2>
<figure><img data-recalc-dims="1" height="1360" width="1360" decoding="async" src="https://i0.wp.com/sixcolors.com/wp-content/uploads/2025/05/Apple-accessibility-features-Live-Listen.png?resize=1360%2C1360&#038;ssl=1" alt="Live Listen" data-image-w="" data-image-h="" class=" jetpack-broken-image"><figcaption>Live Listen can now display captions for people talking around you.</figcaption></figure>
<p>Two updates to existing features are intended to enhance the experience of users of Live Listen and Background Sounds, both on iOS. To the existing Background Sounds feature, which creates a soundscape intended to facilitate concentration, users can now add a timer or control the feature’s behavior with new Shortcuts actions. Live Listen users will be able to start and stop a session remotely when the listening iPhone is located across the room. Captions for Live Listen sessions will also be available on the Apple Watch if the user chooses to use them.</p>
<h2>Mobility</h2>
<figure><img data-recalc-dims="1" height="1360" width="971" decoding="async" src="https://i0.wp.com/sixcolors.com/wp-content/uploads/2025/05/Apple-accessibility-features-Head-Tracking.png?resize=971%2C1360&#038;ssl=1" alt="Head Tracking" data-image-w="" data-image-h="" class=" jetpack-broken-image"><figcaption>Head Tracking features have been improved.</figcaption></figure>
<p>Eye tracking, a feature introduced to iOS and macOS in 2024, will receive a boost from integration with Switch Control, enabling users with mobility impairments to utilize a combination of switches and eye tracking that works best for them.</p>
<h2>Speech</h2>
<p>Personal Voice, which uses artificial intelligence to create a “cloned” version of your voice — useful in the event of speech loss — will receive a speech-quality upgrade and be quicker to set up. Instead of 150 training phrases and an overnight wait to create a new voice, Personal Voice will only require 10 phrases and a few minutes to fully train. Spanish voicing will also be available in the United States and Mexico.</p>
<h2>And more</h2>
<p>Apple’s press release offers hints at many more features, including the ability to temporarily share a group of accessibility settings when using someone else’s Apple device, making it easy to pick up any phone or iPad and use it in exactly the way the user expects.</p>
