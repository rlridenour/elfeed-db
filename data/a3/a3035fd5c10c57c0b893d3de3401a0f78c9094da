<p>You're facing a first starting point to learn Docker from scratch where practice takes priority over theory. The objective of this article is NOT to teach you all aspects, there are already many more complete and in-depth courses. We'll cover the basic and essential aspects so you can start using Docker in your software development projects. We'll go step by step until we manage to run a Python script inside a Docker container.</p>
<p>I'm going to assume you've installed Docker on your machine. If not, you can follow the official instructions at <a href="https://docs.docker.com/get-docker/">docs.docker.com/get-docker</a>.</p>
<p>When running:</p>
<pre class="highlight"><code class="language-bash">docker --version</code></pre>
<p>You should see something similar to:</p>
<pre class="highlight"><code class="language-plain">Docker version 28.4.0, build d8eb465</code></pre>
<p>The version and build may vary, but we must verify that we're able to run Docker commands from the terminal.</p>
<p>Let's begin!</p>
<h2 id="blog-single-content__title--what-is-docker-and-why-use-it" class="blog-single__content-title">What is Docker and why use it?</h2>
<p>Docker is the most popular containerization platform. It allows you to package applications to make them easy to launch. This way you can run your code on any operating system that supports Docker, without worrying about dependencies, versions or environment configurations. Once configured, anyone on your team will be able to launch the application identically.</p>
<p>You shouldn't confuse it with a virtual machine. Although they may seem similar at first glance, Docker containers are isolated processes that use the host operating system's kernel, while virtual machines emulate a complete operating system. This difference is key as it explains their lightweight nature and performance similar to a native application.</p>
<p>Therefore, we achieve:</p>
<ul>
<li><strong>Portability</strong>: Runs on any system with Docker installed</li>
<li><strong>Security</strong>: Each process has its own environment</li>
<li><strong>Efficiency</strong>: Similar, or equal, to running natively</li>
<li><strong>Consistency</strong>: The environment is identical in development, testing and production</li>
</ul>
<p>Now that we understand what Docker is and its benefits, let's see how it works.</p>
<h2 id="blog-single-content__title--docker-architecture" class="blog-single__content-title">Docker Architecture</h2>
<p>The main components are:</p>
<ul>
<li><strong>Docker Engine</strong>: The engine that runs the containers. It's responsible for creating, running and managing containers.</li>
<li><strong>Docker Client</strong>: Command-line interface (CLI) to interact with Docker Engine.</li>
<li><strong>Docker Daemon</strong>: Background process that manages images and containers.</li>
</ul>
<p>When you work with Docker, you mainly interact with the Docker Client, which sends commands to the Docker Daemon to execute actions.</p>
<p>When managing your applications with Docker Client, you'll continuously manage 2 fundamental elements:</p>
<ul>
<li><strong>Image</strong>: Immutable template containing code and dependencies. Think of it as a "class".</li>
<li><strong>Container</strong>: Running instance of an image. It would be the "object" created from the class.</li>
</ul>
<p>You now know the basics about Docker. Let's get practical!</p>
<h2 id="blog-single-content__title--docker-cli-basic-commands" class="blog-single__content-title">Docker CLI Basic Commands</h2>
<p>It's time to learn the basic commands.</p>
<h3 id="blog-single-content__title--running-your-first-container" class="blog-single__content-title">Running your first container</h3>
<p>The "hello world" of Docker is:</p>
<pre class="highlight"><code class="language-bash">docker run hello-world</code></pre>
<p>It will download a small image and run a container that prints a welcome message.</p>
<p>If everything went well, we can move to something more advanced.</p>
<pre class="highlight"><code class="language-bash"># Will download the Debian image and open a bash terminal inside the container
docker run -it debian bash
# Check the version
cat /etc/debian_version
# Exit the container
exit</code></pre>
<p>We're now able to run containers. We're closer to being able to launch our Python script.</p>
<h3 id="blog-single-content__title--container-management" class="blog-single__content-title">Container management</h3>
<p>Let's see some useful commands to manage containers. Raise the Debian container again and in a new terminal execute:</p>
<pre class="highlight"><code class="language-bash"># List active containers
docker ps

# List all containers, including stopped ones
docker ps -a

# Stop a container
docker stop &lt;container_id&gt;

# Remove a container
docker rm &lt;container_id&gt;

# Remove all stopped containers
docker container prune</code></pre>
<h3 id="blog-single-content__title--execution-modes" class="blog-single__content-title">Execution modes</h3>
<p>When we raised the Debian container, you may have wondered what does the <code>-it</code> flag mean? It's the execution mode, or how we interact with the container:</p>
<ul>
<li><strong>Interactive</strong> (<code>-it</code>): To work inside the container. Allows opening a terminal and executing commands manually.</li>
<li><strong>Detached</strong> (<code>-d</code>): Runs in the background. Ideal for services or applications that must always be active but without direct interaction.</li>
</ul>
<pre class="highlight"><code class="language-bash"># Interactive mode
docker run --rm -it eggplanter/sh-tetris:v2.1.0

# Detached mode
docker run -d -p 3000:80 excalidraw/excalidraw</code></pre>
<p>Open <code>http://localhost:3000</code> in your browser to draw with Excalidraw.</p>
<p>And how do I stop the container in detached mode? Very easy, let's remember the management commands:</p>
<pre class="highlight"><code class="language-bash">docker ps
docker stop &lt;container_id&gt;</code></pre>
<h3 id="blog-single-content__title--logs-and-debugging" class="blog-single__content-title">Logs and debugging</h3>
<p>If you need to see what's happening inside a container, logs are your best friend.</p>
<pre class="highlight"><code class="language-bash"># View logs of a container
docker logs &lt;container_id&gt;

# Follow logs in real-time
docker logs -f &lt;container_id&gt;</code></pre>
<h3 id="blog-single-content__title--executing-commands-inside-containers" class="blog-single__content-title">Executing commands inside containers</h3>
<p>Suppose I have the Debian container running in detached mode and I want to use its <code>curl</code> command to make an HTTP request.</p>
<p>You have 2 options:</p>
<pre class="highlight"><code class="language-bash"># Open an interactive shell
docker exec -it &lt;container_id&gt; bash
# And inside
curl rate.sx/btc

# Execute in a single command
docker exec &lt;container_id&gt; curl rate.sx/btc</code></pre>
<h2 id="blog-single-content__title--working-with-images" class="blog-single__content-title">Working with Images</h2>
<p>We're using different images (debian, hello-world, excalidraw...), but where are those images? How do they work?</p>
<p>You can search and download them from <a href="https://hub.docker.com/">Docker Hub</a>, the largest public repository of Docker images.</p>
<p>You can also use the CLI.</p>
<pre class="highlight"><code class="language-bash">docker search python</code></pre>
<p>Each image has a name and a tag that indicates the version or variant. If you don't specify a tag, Docker will use <code>latest</code> by default.</p>
<p>Let's enter the Python prompt using the official image:</p>
<pre class="highlight"><code class="language-bash">docker run -it python:alpine python</code></pre>
<p>The <code>alpine</code> version is a lightweight variant based on Alpine Linux, ideal for reducing image size. However, occupying less space doesn't mean it has all libraries or that its performance is better. Each image is optimized for different use cases.</p>
<h2 id="blog-single-content__title--sharing-data-between-host-and-container-bind-mounts" class="blog-single__content-title">Sharing data between host and container: Bind mounts</h2>
<p>Suppose we have a Python script on our computer and we want to run it inside a container.</p>
<p><code>script.py</code> contains the following code:</p>
<pre class="highlight"><code class="language-python">print("Hello from the Docker container!")</code></pre>
<p>To run this script inside a Python container, we can use many strategies in Docker. The simplest is to use a bind mount to share the file between the host and the container.</p>
<pre class="highlight"><code class="language-bash">docker run --rm -v $(pwd)/script.py:/app/script.py python:alpine python /app/script.py</code></pre>
<p>The key is in the <code>-v</code> flag. The two dots separate the host path (left) and the path inside the container (right). In this case, we're mounting <code>$(pwd)/script.py</code> to <code>/app/script.py</code> inside the container. <code>$(pwd)</code> is an environment variable that represents the current directory, or where we executed the command. <code>--rm</code> indicates that the container will be automatically deleted after it finishes running.</p>
<p>And voil√†! You should see the message:</p>
<pre class="highlight"><code class="language-plain">Hello from the Docker container!</code></pre>
<p>Congratulations! You've run your first Python script inside a Docker container.</p>
<p>We've launched a very simple example. What would happen if our script had external dependencies? Or if we wanted to configure it to run automatically without an intricate <code>docker run</code> command? We need to create our own Docker images.</p>
<h2 id="blog-single-content__title--creating-your-own-images" class="blog-single__content-title">Creating Your Own Images</h2>
<p><code>Dockerfile</code> files are the standard way to define how to build a custom Docker image.</p>
<p>An example for what we've done so far would be:</p>
<pre class="highlight"><code class="language-dockerfile">FROM python:alpine
WORKDIR /app
COPY script.py .
CMD ["python", "script.py"]</code></pre>
<p>We would build the image with:</p>
<pre class="highlight"><code class="language-bash">docker build -t my-python-script:v1 .</code></pre>
<p>Don't forget the dot at the end!</p>
<p>And we would run it with:</p>
<pre class="highlight"><code class="language-bash">docker run --rm my-python-script:v1</code></pre>
<p>It's the same as before, but now we have a reusable image. We could share it with other colleagues or deploy it in production.</p>
<p>You can use the following basic instructions in a Dockerfile:</p>
<ul>
<li><strong>FROM</strong>: Defines the base image</li>
<li><strong>RUN</strong>: Executes commands during the build (install packages)</li>
<li><strong>COPY</strong>: Copies files from the host to the image</li>
<li><strong>ADD</strong>: Similar to COPY but with additional capabilities (decompress files)</li>
<li><strong>CMD</strong>: Default command when starting the container</li>
<li><strong>ENTRYPOINT</strong>: Main command that isn't easily overwritten</li>
</ul>
<p>Now let's make it a bit more complicated.</p>
<p>We create a file called <code>requirements.txt</code> with the dependencies:</p>
<pre class="highlight"><code class="language-txt">names</code></pre>
<p>It's a library that generates random names.</p>
<p>We modify our <code>script.py</code> to use it:</p>
<pre class="highlight"><code class="language-python">import names
print(names.get_full_name())</code></pre>
<p>We modify the <code>Dockerfile</code> to install the dependencies:</p>
<pre class="highlight"><code class="language-dockerfile">FROM python:alpine
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY script.py .
CMD ["python", "script.py"]</code></pre>
<p>We build and run again:</p>
<pre class="highlight"><code class="language-bash">docker build -t my-python-script:v2 .</code></pre>
<p>And we launch:</p>
<pre class="highlight"><code class="language-bash">docker run --rm my-python-script:v2</code></pre>
<p>You should see a random name generated by the <code>names</code> library.</p>
<p>You've managed to create a container to run your Python script with dependencies. Good job!</p>
<p>What files would we upload to the repository or pass to a colleague?</p>
<ul>
<li><code>Dockerfile</code>: The file with the instructions to build the image.</li>
<li><code>script.py</code>: The Python script we want to run.</li>
<li><code>requirements.txt</code>: The dependencies needed for the script.</li>
<li><code>README.md</code>: Optionally, a documentation file with instructions to build and run the image.</li>
</ul>
<p>But no binary or heavy Docker image. Each person can build the image locally.</p>
<h2 id="blog-single-content__title--extra-environment-variables" class="blog-single__content-title">Extra: Environment variables</h2>
<p>It's not always a good idea to hardcode configurations inside the code or the Dockerfile. For example passwords, tokens or URLs that will change depending on the environment (development, testing, production). That's why Docker natively supports environment variables.</p>
<p>The most common is to use a <code>.env</code> file:</p>
<pre class="highlight"><code class="language-env">DATABASE_PASSWORD=mysecretpassword
API_KEY=abcdef</code></pre>
<p>And we use it when running the container:</p>
<pre class="highlight"><code class="language-bash">docker run --rm --env-file .env my-python-script:v3</code></pre>
<p>They will only work inside the container. In Python you can access them using the <code>os</code> module:</p>
<pre class="highlight"><code class="language-python">import os

db_password = os.getenv("DATABASE_PASSWORD")
api_key = os.getenv("API_KEY")
print(f"DB Password: {db_password}, API Key: {api_key}")</code></pre>
<p>Happy containerizing!</p>