
<p>Paul Kafasis:</p>

<blockquote>
  <p>Since they were first enabled last year, I have frequently found
Apple Intelligence’s notification summaries for emails to be
something less than helpful. Here are some I spotted in just the
past few days.</p>
</blockquote>

<p>The first one of these is particularly interesting because it highlights a key area where LLMs are frustratingly stupid. Kafasis got a notification summary from Apple Intelligence claiming “Package shipped for $427 order” for a used book he’d purchased. The email from Amazon, from which Apple Intelligence gleaned the information, had the price formatted thus: $4²⁷ — omitting the decimal and putting the cents in superscript. That’s a centuries-old formatting idiom for prices that remains common — <a href="https://duckduckgo.com/?q=walmart+price+sign&amp;iax=images&amp;ia=images">e.g. at Walmart</a> — to this day. But Apple Intelligence just sees dollar-sign, four, two, seven, and thus $427.</p>

<p>That’s just stupid.</p>

<p>But where it really gets frustrating is that everyone has to learn this at some point. If you were at Walmart with a kid, and the kid asked why, say, dog food is so expensive, pointing to a sign that says it cost $9⁸⁷ per bag, you’d explain it, once, and the kid would never forget it. “<em>Oh, that’s just another way of writing nine dollars and eighty-seven cents — they do it that way to emphasize the dollar amount and de-emphasize the cents, which really don’t matter.</em>” This would make intuitive sense to the child as well, because they know dog food probably costs about $10 per bag, not $1,000 per bag.</p>

<p>There is no way to properly explain something like this to an LLM (yet?). You can’t teach it like we do with children. Or at least you can’t do it in a way that jibes with our human sense of “learning” — it’s more like how the Guy Pearce protagonist “learns” in Christopher Nolan’s <em><a href="https://www.themoviedb.org/movie/77-memento?language=en-US">Memento</a></em>. <em>Here, tattoo another thing to remember on your arm.</em> But at least ChatGPT is <em>trying</em> to learn about us, albeit in its crude <em>Memento</em>-like way. With Apple Intelligence in particular, you can’t teach it <em>at all</em>. There’s no place in the system where you can correct the very simple, easily-explained mistake it made upon seeing <em>$4²⁷</em> in an email. The next time an email from Amazon comes with a price formatted like that, Apple Intelligence is likely to summarize it the exact same wrong way — off by a factor of 100 — again. And there’s nothing we can do about it.</p>

<div>
<a  title="Permanent link to ‘Notification Summary Miscues’"  href="https://daringfireball.net/linked/2025/03/25/notification-summary-miscues">&nbsp;★&nbsp;</a>
</div>

	