<div class="media-wrapper"><img decoding="async" src="https://cdn.macstories.net/friday-28-nov-2025-12-21-29-1764328902816.png" alt="Different experiences with app connectors in Claude, Perplexity, and ChatGPT."><p class="image-caption">Different experiences with app connectors in Claude, Perplexity, and ChatGPT.</p></div>
<p id="p2">I was catching up on different articles after the release of <a href="https://www.anthropic.com/news/claude-opus-4-5" rel="noopener noreferrer">Claude Opus 4.5</a> earlier this week, and this part from <a href="https://simonwillison.net/2025/Nov/24/claude-opus/" rel="noopener noreferrer">Simon Willison&rsquo;s blog post about it</a> stood out to me:</p>
<blockquote id="blockquote3"><p>
  I&rsquo;m not saying the new model isn&rsquo;t an improvement on Sonnet 4.5&mdash;but I can&rsquo;t say with confidence that the challenges I posed it were able to identify a meaningful difference in capabilities between the two.</p>
<p>  This represents a growing problem for me. My favorite moments in AI are when a new model gives me the ability to do something that simply wasn&rsquo;t possible before. In the past these have felt a lot more obvious, but today it&rsquo;s often very difficult to find concrete examples that differentiate the new generation of models from their predecessors.
</p></blockquote>
<p id="p4">This is something that I&rsquo;ve felt every few weeks (with each new model release from the <a href="https://en.wikipedia.org/wiki/List_of_artificial_intelligence_companies" rel="noopener noreferrer">major AI labs</a>) over the past year: if you&rsquo;re <em>really</em> plugged into this ecosystem, it can be hard to spot meaningful differences between major models on a release-by-release basis. That&rsquo;s not to say that real progress in intelligence, knowledge, or tool-calling isn&rsquo;t being made: benchmarks and evaluations performed by established organizations <a href="https://artificialanalysis.ai/" rel="noopener noreferrer">tell a clear story</a>. At the same time, it&rsquo;s also worth keeping in mind that more companies these days may be <a href="https://www.seangoedecke.com/are-new-models-good/" rel="noopener noreferrer">optimizing their models</a> for benchmarks to come out on top and, more importantly, that the vast majority of folks don&rsquo;t have a suite of personal benchmarks to evaluate different models for their workflows. Simon Willison thinks that people who use AI for work should create personalized test suites, which is something I&rsquo;m going to consider for prompts that I use frequently. I also feel like <a href="https://www.oneusefulthing.org/p/an-opinionated-guide-to-using-ai" rel="noopener noreferrer">Ethan Mollick&rsquo;s advice</a> of picking a reasoning model and checking in every few months to reassess AI progress is probably the best strategy for most people who don&rsquo;t want to tweak their AI workflows every other week.</p>
<p id="p5"><!--more--></p>
<p id="p6">As I was thinking about this, I also came across <a href="https://birchtree.me/blog/eating-my-words/" rel="noopener noreferrer">this post by Matt Birchler</a> (paywall, and <a href="https://birchtree.me/blog/more-birchtree-less-money/" rel="noopener noreferrer">a highly recommended one</a>, too):</p>
<blockquote id="blockquote7"><p>
  That said, ChatGPT has been the number one app in the App Store basically since it launched a couple of years ago. And as I write this today, Google&rsquo;s Gemini is number two, and xAI&rsquo;s Grok is number six. And I think that these are gonna be here to stay. The fact that these are a blank canvas, you can enter basically anything into it and get useful information out of it, has proven incredibly compelling to everyday people. Let&rsquo;s remember that ChatGPT is not baked into the iPhone. People are actively going to the App Store to download this app. And so, I truly think this chat interface is gonna be with us for a long time because it allows such a variety of functionality that can tailor itself to each individual user.
</p></blockquote>
<p id="p8">And this post by Sebastiaan de With (X link):</p>
<blockquote class="twitter-tweet" id="blockquote9">
<p lang="en" dir="ltr">The only meaningful distinguishing quality in AI right now as models become a commodity is being better at making new / great interfaces. </p>
<p>The OpenAI team is very good at this: <a href="https://t.co/D4o1J5QGZh" rel="noopener noreferrer">https://t.co/D4o1J5QGZh</a></p>
<p>&mdash; Sebastiaan de With (@sdw) <a href="https://twitter.com/sdw/status/1993402033777598729?ref_src=twsrc%5Etfw" rel="noopener noreferrer">November 25, 2025</a></p></blockquote>
<p id="p10"><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p id="p11">Both of these ideas have been on my mind a lot: the modern flavor of chatbot UIs clearly resonate with people because the LLM experience has gotten <em>good enough</em> across the board to be useful, especially with the addition of web search and <a href="https://artificialanalysis.ai/evaluations/omniscience" rel="noopener noreferrer">reduced hallucinations</a>; and, since the baseline is now <em>good enough</em>, the app experience and how LLMs are woven into a people&rsquo;s daily lives and workflows will be <em>the</em> differentiators going forward.</p>
<p id="p12">As I mentioned on <a href="https://www.relay.fm/connected/579" rel="noopener noreferrer">Connected</a> last week, my version of this is that, personally, I &ldquo;vibe&rdquo; more with Claude than other LLMs. I prefer its design and <a href="https://www.macstories.net/stories/early-impressions-of-claude-opus-4-and-using-tools-with-extended-thinking/" rel="noopener noreferrer">interleaved thinking</a> approach; I like that Anthropic doesn&rsquo;t have image or video generation products (which I find despicable); and, of course, Claude&rsquo;s <a href="https://www.macstories.net/linked/claudes-chat-history-and-app-integrations-as-a-form-of-lock-in/" rel="noopener noreferrer">ecosystem of app integrations</a> and <a href="https://www.claude.com/blog/skills" rel="noopener noreferrer">skills</a> means that I can use it as a new form of <a href="https://appstories.net/posts/our-latest-app-and-automation-experiments" rel="noopener noreferrer">non-deterministic automation</a> that lets me work faster. By the same token, that&rsquo;s why &ndash; despite its <a href="https://artificialanalysis.ai/articles/gemini-3-pro-everything-you-need-to-know" rel="noopener noreferrer">widely documented advancements</a> &ndash; I don&rsquo;t like chatting or working with Gemini: I&rsquo;m not a fan of how it responds, its chat UI, and its lack of app connectors.</p>
<p id="p13">At the same time, I also recognize that OpenAI knows how to design polished interactions for hundreds of millions of people (their voice mode is unparalleled, and I have high hopes for <a href="https://www.macstories.net/linked/apps-in-chatgpt/" rel="noopener noreferrer">ChatGPT Apps</a>). And I also like to complement Claude&rsquo;s lackluster web search features with Perplexity and ChatGPT Pro (Silvia and I share a team plan as a &ldquo;fake&rdquo; family subscription, and we have limited access to the Pro model), both of which can reference more sources when I&rsquo;m doing deep research on any given topic.</p>
<p id="p14">Which brings me to my takeaway: from my perspective, despite a stronger baseline, <strong>there is still no single LLM that &ldquo;does it all&rdquo; these days</strong>. Beyond <a href="https://www.macstories.net/notes/ai-experiments-fast-inference-with-groq-and-third-party-tools-with-kimi-k2-in-typingmind/" rel="noopener noreferrer">my nerdy experiments</a>, I generally alternate between two modes: Claude for most work-related tasks, and either ChatGPT or Perplexity for web search. The combination of these two modalities gives me everything I need from modern LLMs, and it provides me with the mix of performance, design, and app integrations I like best.</p>
<p id="p15">Ultimately, choosing between any LLM at the frontier of AI right now is a highly subjective matter that comes down to cost, workflow, app ecosystem, design, and, yes, pure &ldquo;vibes&rdquo;. Personally, I try to avoid fixating on benchmarks and instead prioritize these qualities in my decisions.</p>
<p id="p16">It&rsquo;s hard to differentiate between recent LLM releases of major models if you look at benchmarks alone. However, if you consider <em>other</em> factors beyond <a href="https://www.swebench.com/SWE-bench/" rel="noopener noreferrer">coding benchmarks</a> and abstract numbers, there are plenty of practical differences between the major AI apps right now that are worth exploring and judging for yourself.</p>
