<p><em>Ethics: An International Journal of Social, Political, and Legal Philosophy</em> has published its policy regarding the use of artificial intelligence (AI) by authors, editors, and reviewers. <span id="more-55833"></span></p>
<p><img loading="lazy" decoding="async" class="wp-image-55835 aligncenter" src="https://dailynous.com/wp-content/uploads/2025/12/ethics-cover-inspection.png" alt="" width="755" height="500" srcset="https://dailynous.com/wp-content/uploads/2025/12/ethics-cover-inspection.png 1139w, https://dailynous.com/wp-content/uploads/2025/12/ethics-cover-inspection-300x199.png 300w, https://dailynous.com/wp-content/uploads/2025/12/ethics-cover-inspection-1024x678.png 1024w, https://dailynous.com/wp-content/uploads/2025/12/ethics-cover-inspection-768x508.png 768w, https://dailynous.com/wp-content/uploads/2025/12/ethics-cover-inspection-400x265.png 400w" sizes="auto, (max-width: 755px) 100vw, 755px" /></p>
<p><a href="https://sites.google.com/site/dwportmore/" target="_blank" rel="noopener">Douglas Portmore</a> (Notre Dame), editor-in-chief of <em>Ethics</em>, had shared some preliminary thoughts on the matter in an earlier issue of the journal, <a href="https://dailynous.com/2025/09/29/editor-of-ethics-floats-ai-use-guidelines/">discussed at length here</a>.</p>
<p>The <a href="https://www.journals.uchicago.edu/journals/et/ai-policy?" target="_blank" rel="noopener">official policy</a> is divided into guidelines for contributors and guidelines for editors and reviewers, and notes that &#8220;editors reserve the right to sanction those who fail to [comply with the policy], possibly by banning them from reviewing for or submitting to <em>Ethics</em>.&#8221;</p>
<p>Here are the guidelines for <strong>contributors</strong>:</p>
<p style="padding-left: 40px;"><em>AI tools cannot author or even co-author a submission. Authors and co-authors must take full moral and legal responsibility for their submissions; they must take responsibility for the assertions that they make, the arguments that they proffer, and the sources that they cite or fail to cite. Since AI tools cannot take responsibility, </em>Ethics <em>will not consider submissions that have been authored or co-authored by an AI. </em></p>
<p style="padding-left: 40px;"><em>Authors must never take credit for work that’s not their own. Taking sentences of text from a generative AI tool and presenting them as your own words is plagiarism—at least, insofar as we take plagiarism to be a form of intellectual dishonesty in which one takes credit for work that’s not one’s own. Using generative AI to come up with a list of objections to a thesis or argument and presenting them as your own is also plagiarism. Consequently, authors who use text, images, or other content generated by an AI in their submission must be transparent about this, disclosing which tools were used and how. In cases where an original human source cannot be identified, authors should, then, include something like the following note: “I first became aware of this objection through the use of ChatGPT, OpenAI, April 16, 2025, https://chat.openai.com/chat.”</em></p>
<p style="padding-left: 40px;"><em>It’s important not only that authors avoid taking credit for work that is not their own but also that they give credit where credit is due. The problem with merely citing an AI tool—say, as the source of an example or objection—is that the AI tool may not be the original source. The original source may instead be an author whose work was used to train that AI tool. Thus, attributing some example or objection to ChatGPT could be just as problematic as attributing an objection to your colleague when all they did was tell you about some objection that Rawls raised. Thus, authors may need to track down the original source of an example or objection generated by an AI tool and cite it.</em></p>
<p style="padding-left: 40px;"><em>The editors of </em>Ethics <em>value human creativity; we, therefore, value work that presents the author’s own original ideas and insights more than work that presents ideas and insights that don’t originate with the author. For this reason, content that does not originate with the author may be deemed less desirable and publishable—at least, other things being equal.</em></p>
<p>Here are the guidelines for <strong>editors and reviewers</strong>:</p>
<p style="padding-left: 40px;"><em>Submissions to </em>Ethics <em>are confidential. Thus, editors and reviewers must be careful to maintain confidentiality and protect the author’s intellectual property. Just as sharing a submission with a colleague would violate confidentiality, so too would uploading it (or any part of it) to external services that lack the access controls needed to preserve confidentiality. The editors of </em>Ethics <em>have agreed not to upload submissions to such external servers nor to use AI tools to assess them.</em></p>
<p style="padding-left: 40px;"><em>Those who agree to review for </em>Ethics <em>do so under the implicit understanding that they will provide the editors with their own independent assessment of the submission, an opinion that is based solely on their own reading of the manuscript. Thus, it would be inappropriate for a reviewer to base their assessment of a submission, even in part, on an AI’s summary of it. And it would certainly be inappropriate to use an AI tool to generate any part of their report or assessment.</em></p>
<p>Discussion welcome, as are links to or excerpts from other journals&#8217; AI policies.</p><p>The post <a href="https://dailynous.com/2025/12/03/ethics-announces-ai-policy/">Ethics Announces AI Policy</a> first appeared on <a href="https://dailynous.com">Daily Nous</a>.</p>