<p>I&rsquo;ve been a busy little bee in the last few days, so quite a few improvements to <code>ollama-buddy</code>, my Emacs LLM <code>ollama</code> client, they are listed below:</p>
<figure><img src="https://emacs.dyerdwelling.family/ox-hugo/ollama-buddy-banner.jpg" width="100%">
</figure>

<h2 id="0-dot-5-dot-1"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-03-07 Fri&gt; </span></span> <strong>0.5.1</strong></h2>
<p>Added temperature control</p>
<ul>
<li>Implemented temperature control parameter</li>
<li>Added menu commands for setting (T), resetting (0)</li>
<li>Added keybindings (C-c t/T/0) for quick temperature adjustments</li>
<li>Updated header line and prompt displays to show current temperature</li>
<li>Included temperature info in welcome screen with usage guidance</li>
</ul>
<p>This addition gives users fine-grained control over the creativity and randomness of their AI responses through a new temperature variable.</p>
<p>This update adds several convenient ways to control temperature in Ollama-Buddy:</p>
<p><strong>Key Features</strong></p>
<ol>
<li>
<p><strong>Direct Temperature Setting</strong>: Use <code>C-c t</code> from the chat buffer or the menu command <code>[T]</code> to set an exact temperature value between 0.0 and 2.0.</p>
</li>
<li>
<p><strong>Preset Temperatures</strong>: Quickly switch between common temperature presets with <code>C-c T</code> from the chat buffer:</p>
<ul>
<li>Precise (0.1) - For factual responses</li>
<li>Focused (0.3) - For deterministic, coherent outputs</li>
<li>Balanced (0.7) - Default setting</li>
<li>Creative (0.9) - For more varied, creative responses</li>
</ul>
</li>
<li>
<p><strong>Reset to Default</strong>: Return to the default temperature (0.7) with <code>C-c 0</code> or the menu command <code>[0]</code>.</p>
</li>
<li>
<p><strong>Visual Feedback</strong>: The current temperature is displayed in the header line and before each response, so you always know what setting you&rsquo;re using.</p>
</li>
</ol>
<h2 id="0-dot-5-dot-0"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-03-06 Thu&gt; </span></span> <strong>0.5.0</strong></h2>
<p>Implemented session management, so you can now save your conversations and bring them back with the relevant context and chat history!</p>
<ul>
<li>Chat history is now maintained separately for each model</li>
<li>Added session new/load/save/delete/list functionality</li>
<li>A switch in context can now be achieved by any of the following methods:
<ul>
<li>Loading a previous session</li>
<li>Creating a new session</li>
<li>Clearing history on the current session</li>
<li>Toggling history on and off</li>
</ul>
</li>
</ul>
<p><strong>Key Benefits</strong></p>
<ul>
<li>More relevant responses when switching between models</li>
<li>Prevents context contamination across different models</li>
<li>Clearer session management and organization</li>
</ul>
<p><strong>Key Features</strong></p>
<ol>
<li><strong>Session Management</strong></li>
</ol>
<p>With session management, you can now:</p>
<ul>
<li>
<p><strong>Save session</strong> with <code>ollama-buddy-sessions-save</code> (or through the ollama-buddy-menu) Preserve your current conversation with a custom name</p>
</li>
<li>
<p><strong>Load session</strong> with <code>ollama-buddy-sessions-load</code> (or through the ollama-buddy-menu) Return to previous conversations exactly where you left off</p>
</li>
<li>
<p><strong>List all sessions</strong> with <code>ollama-buddy-sessions-list</code> (or through the ollama-buddy-menu) View all saved sessions with metadata including timestamps and models used</p>
</li>
<li>
<p><strong>Delete session</strong> with <code>ollama-buddy-sessions-delete</code> (or through the ollama-buddy-menu) Clean up sessions you no longer need</p>
</li>
<li>
<p><strong>New session</strong> with <code>ollama-buddy-sessions-new</code>  (or through the ollama-buddy-menu) Begin a clean slate without losing your saved sessions</p>
</li>
<li>
<p><strong>Menu Commands</strong></p>
</li>
</ul>
<p>The following commands have been added to the <code>ollama-buddy-menu</code>:</p>
<ul>
<li><code>E</code> New session</li>
<li><code>L</code> Load session</li>
<li><code>S</code> Save session</li>
<li><code>Y</code> List sessions</li>
<li><code>K</code> Delete session</li>
</ul>
<h2 id="0-dot-4-dot-1"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-03-04 Tue&gt; </span></span> <strong>0.4.1</strong></h2>
<p>Added a sparse version of <code>ollama-buddy</code> called <code>ollama-buddy-mini</code>, see the github repository for the elisp file and a description in <code>README-mini.org</code></p>
<h2 id="0-dot-4-dot-0"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-03-03 Mon&gt; </span></span> <strong>0.4.0</strong></h2>
<p>Added conversation history support and navigation functions</p>
<ul>
<li>Implemented conversation history tracking between prompts and responses</li>
<li>Added configurable history length limits and visual indicators</li>
<li>Created navigation functions to move between prompts/responses in buffer</li>
</ul>
<p><strong>Key Features</strong></p>
<ol>
<li><strong>Conversation History</strong></li>
</ol>
<p>Ollama Buddy now maintains context between your interactions by:</p>
<ul>
<li>Tracking conversation history between prompts and responses</li>
<li>Sending previous messages to Ollama for improved contextual responses</li>
<li>Displaying a history counter in the status line showing conversation length</li>
<li>Providing configurable history length limits to control memory usage</li>
</ul>
<p>You can control this feature with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-elisp" data-lang="elisp"><span style="display:flex;"><span><span style="color:#75715e">;; Enable/disable conversation history (default: t)</span>
</span></span><span style="display:flex;"><span>(setq ollama-buddy-history-enabled <span style="color:#66d9ef">t</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">;; Set maximum conversation pairs to remember (default: 10)</span>
</span></span><span style="display:flex;"><span>(setq ollama-buddy-max-history-length <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">;; Show/hide the history counter in the header line (default: t)</span>
</span></span><span style="display:flex;"><span>(setq ollama-buddy-show-history-indicator <span style="color:#66d9ef">t</span>)
</span></span></code></pre></div><ol>
<li><strong>Enhanced Navigation</strong></li>
</ol>
<p>Moving through longer conversations is now much easier with:</p>
<ul>
<li>
<p>Navigation functions to jump between prompts using C-c n/p</p>
</li>
<li>
<p><strong>Menu Commands</strong></p>
</li>
</ul>
<p>Three new menu commands have been added:</p>
<ul>
<li><code>H</code>: Toggle history tracking on/off</li>
<li><code>X</code>: Clear the current conversation history</li>
<li><code>V</code>: View the full conversation history in a dedicated buffer</li>
</ul>
<h2 id="0-dot-3-dot-1"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-03-02 Sun&gt; </span></span> <strong>0.3.1</strong></h2>
<p>Enhanced model colour contrast with themes, allowing <code>ollama-buddy-enable-model-colors</code> to be enabled by default.</p>
<h2 id="0-dot-3-dot-0"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-03-01 Sat&gt; </span></span> <strong>0.3.0</strong></h2>
<p>Added real-time token usage tracking and display</p>
<ul>
<li>Introduce variables to track token counts, rates, and usage history</li>
<li>Implement real-time token rate updates with a timer</li>
<li>Add a function to display token usage statistics in a dedicated buffer</li>
<li>Allow toggling of token stats display after responses</li>
<li>Integrate token tracking into response processing and status updates</li>
<li>Ensure cleanup of timers and tracking variables on completion or cancellation</li>
</ul>
<p><strong>Key Features</strong></p>
<ol>
<li>
<p><strong>Menu Commands</strong></p>
<p>The following command has been added to the <code>ollama-buddy-menu</code>:</p>
<ul>
<li><code>t</code> Show a summary of token model usage stats</li>
</ul>
</li>
</ol>
<h2 id="0-dot-2-dot-4"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-02-28 Fri&gt; </span></span> <strong>0.2.4</strong></h2>
<p>Added model-specific color highlighting</p>
<ul>
<li>Introduce `ollama-buddy-enable-model-colors` (default: nil) to toggle model-based color highlighting.</li>
<li>Assign consistent colors to models based on string hashing.</li>
<li>Apply colors to model names in the menu, status, headers, and responses.</li>
<li>Add `ollama-buddy-toggle-model-colors` command to toggle this feature.</li>
</ul>
<p>This enhancement aims to improve user experience by visually distinguishing different AI models within the interface.</p>
<p>Note: I am likely to use both <strong>colour</strong> and <strong>color</strong> interchangeably in the following text! :)</p>
<p><strong>Key Features</strong></p>
<ol>
<li>
<p><strong>Model-Specific Colors</strong></p>
<ul>
<li>A new customizable variable, <code>ollama-buddy-enable-model-colors</code>, allows users to enable or disable model-specific colors.</li>
<li>Colors are generated based on a model&rsquo;s name using a hashing function that produces consistent and visually distinguishable hues.</li>
<li>However there could be an improvement regarding ensuring the contrast is sufficient and hence visibility maintained with differing themes.</li>
</ul>
</li>
<li>
<p><strong>Interactive Color Toggle</strong></p>
<ul>
<li>Users can toggle model-specific colors with the command <code>ollama-buddy-toggle-model-colors</code>, providing flexibility in interface customization.</li>
</ul>
</li>
<li>
<p><strong>Colored Model Listings</strong></p>
<ul>
<li>Model names are now displayed with their respective colors in various parts of the interface, including:
<ul>
<li>The status line</li>
<li>Model selection menus</li>
<li>Command definitions</li>
<li>Chat history headers</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Menu Commands</strong></p>
</li>
</ol>
<p>The following command hashing been added to the <code>ollama-buddy-menu</code>:</p>
<ul>
<li><code>C</code> Toggle colors</li>
</ul>
<h2 id="0-dot-2-dot-3"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-02-28 Fri&gt; </span></span> <strong>0.2.3</strong></h2>
<p>Added Prompt History Support</p>
<ul>
<li>Prompts are now integrated into the Emacs history mechanism which means they persist across sessions.</li>
<li>Use <code>M-p</code> to navigate prompt history, and <code>M-p</code> / <code>M-n</code> within the minibuffer to insert previous prompts.</li>
</ul>
<p><strong>Key Features</strong></p>
<ul>
<li>Persistent prompt history</li>
<li>A new variable, <code>ollama-buddy--prompt-history</code>, now keeps track of past prompts. This means you can quickly recall and reuse previous queries instead of retyping them from scratch.</li>
<li><code>M-p</code> - recall a previous prompt in the buffer which will bring up the minibuffer for prompt history selection.</li>
<li>Minibuffer <code>M-p</code> / <code>M-n</code> - Navigate through past prompts when prompted for input.</li>
</ul>
<h2 id="0-dot-2-dot-2"><span class="timestamp-wrapper"><span class="timestamp">&lt;2025-02-27 Thu&gt; </span></span> <strong>0.2.2</strong></h2>
<p>Added support for role-based presets</p>
<ul>
<li>Introduced `ollama-buddy-roles-directory` for storing role preset files.</li>
<li>Implemented interactive functions to manage roles:
<ul>
<li>`ollama-buddy-roles-switch-role`</li>
<li>`ollama-buddy-role-creator-create-new-role`</li>
<li>`ollama-buddy-roles-open-directory`</li>
</ul>
</li>
<li>Added ability to create and switch between role-specific commands.</li>
<li>Updated menu commands to include role management options.</li>
</ul>
<p>This enhancement allows you to create, switch, and manage role-specific command configurations, which basically generates differing menu layouts and hence command options based on your context, making your workflow more personalized and efficient.</p>
<p><strong>What Are Role-Based Presets?</strong></p>
<p>Roles in Ollama Buddy are essentially <strong>profiles</strong> tailored to specific tasks. Imagine you&rsquo;re using Ollama Buddy for:</p>
<ul>
<li><strong>Coding assistance</strong> with one set of prompts</li>
<li><strong>Creative writing</strong> with a different tone and response style</li>
<li><strong>Generating Buffy Style Quips</strong> - just a fun one!</li>
</ul>
<p>With this update, you can now create presets for each of these contexts and switch between them seamlessly without manually re-configuring settings every time. On each switch of context and hence role, a new ollama buddy menu will be generated with the associated keybinding attached to the relevant context commands.</p>
<p><strong>Key Features</strong></p>
<p><strong>1. Store Your Custom Roles</strong></p>
<p>A new directory <code>ollama-buddy-roles-directory</code> (defaulting to <code>~/.emacs.d/ollama-buddy-presets/</code>) now holds your role presets. Each role is saved as an <code>.el</code> file containing predefined <strong>commands</strong>, <strong>shortcuts</strong>, and <strong>model preferences</strong>.</p>
<p><strong>2. Easily Switch Between Roles</strong></p>
<p>With <code>M-x ollama-buddy-roles-switch-role</code> you can pick from available role presets and swap effortlessly between them (or use the menu item from <code>ollama-buddy-menu</code>)</p>
<p><strong>3. Create Custom Roles with Unique Commands</strong></p>
<p>You can now define <strong>custom commands</strong> for each role with <code>M-x ollama-buddy-role-creator-create-new-role</code> (or the menu item from <code>ollama-buddy-menu</code>)</p>
<p>This interactive function allows you to:</p>
<ul>
<li>Assign menu shortcuts to commands</li>
<li>Describe command behaviour</li>
<li>Set a default AI model</li>
<li>Define a system prompt for guiding responses</li>
</ul>
<p>Once saved, your new role is ready to load anytime!</p>
<p><strong>4. Open Role Directory in Dired</strong></p>
<p>Need to tweak a role manually? A simple, run <code>M-x ollama-buddy-roles-open-directory</code> or of course also from the <code>ollama-buddy-menu</code> which opens the presets folder in <strong>dired</strong>, where you can quickly edit, copy, or delete role configurations.</p>
<p><strong>5. Preconfigured presets are available if you&rsquo;d like to use a ready-made setup.</strong></p>
<ul>
<li>ollama-buddy&ndash;preset__buffy.el</li>
<li>ollama-buddy&ndash;preset__default.el</li>
<li>ollama-buddy&ndash;preset__developer.el</li>
<li>ollama-buddy&ndash;preset__janeway.el</li>
<li>ollama-buddy&ndash;preset__translator.el</li>
<li>ollama-buddy&ndash;preset__writer.el</li>
</ul>
<p>If these files are put in the <code>ollama-buddy-roles-directory</code> then the role selection menu will pass through completing-read, and present the following:</p>
<p>{buffy | default | developer | janeway | translator | writer}</p>
<p>With the selection regenerating the <code>ollama-buddy-menu</code> accordingly, and off you go.</p>
<p><strong>6. Menu commands</strong></p>
<p>The following commands have been added to the <code>ollama-buddy-menu</code>:</p>
<ul>
<li><code>R</code> Switch Role</li>
<li><code>N</code> Create New Role</li>
<li><code>D</code> Open Roles Directory</li>
</ul>