<p><strong>Summary: </strong>
A reflection on two presentations I attended around statistical proximity of words/symbols in a corpus, tarot reading, LLM agendas, and thinking.
</p>
        <blockquote class="quote epigraph" data-id="20230712T221352">
<p>
The classics have long been vulnerable to modernist and post-modern raiding
parties.
</p>
<footer>&#8213;Michael Schmidt, <cite>Gilgamesh</cite></footer></blockquote>
<ins class="update margin" role="note" datetime="2025-04-18"><small><em><strong><time datetime="2025-04-18">Apr 18, 2025</time> update:</strong></em></small> 
<p><small>Over at Second Breakfast, <a href="https://2ndbreakfast.audreywatters.com/ai-is-carceral-ed-tech/">AI is Carceral Ed-Tech</a> dives deeper into <span>Large Language Models</span> (<abbr title="Large Language Models">LLMs</abbr> <small><a class="ref" rel="tag opener" aria-label="Other site-wide references of â€œLarge Language Modelsâ€" title="Other site-wide references of â€œLarge Language Modelsâ€" href="https://takeonrules.com/site-map/glossary/#abbr-dfn-LLM">ğŸ“–</a></small>)
as they
are positioned towards capture.</small></p>
</ins>

<p>About once a week or so, I think about a presentation I attended in <time datetime="2023-12" title="2023-12">late 2023</time>
encouraging me and others to use <abbr title="Large Language Models">LLMs</abbr>
 in our day to day work.</p>
<p>The first presenter talked about using <abbr title="Large Language Models">LLMs</abbr>
 to spin up some baseline marketing
talking points.  Another demonstrated using them for research but spoke of the
precarity of citations.<small class="side-container">
  <span class="side-label"><span class="hidden">(</span>Sidenote<span class="hidden">:</span></span>
  <span class="side" role="note"> A red flag in that thereâ€™s an erosion of truth.<span class="hidden">)</span></span>
</small>
</p>
<p>The last presenter demonstrated prompting an <abbr title="Large Language Model">LLM</abbr>
 to generate code for
determining if a number was prime.  Then generated tests for numbers that it
said were either prime or not.  And I saw the equivalent in the assertions:</p>
<pre><code class="language-ruby">assert(is_prime?(23) == false)
</code></pre>
<p>â€¦and the test passed.  On the spot, I called it out as wrong.  I think raising
my voice just a bit in that moment helped inoculate me (and I hope others) from
the â€œsugar highâ€ that was â€œrapid code completion.â€</p>
<p>The three presenters used language akin to â€œtrust but verify.â€  Establishing
trust can be expensive, how can we trust something that spits out
implementations faster than we can verify?</p>
<p>And then, during the question and answer, I further challenged the wisdom of
using these tools.  Especially given the context that some were using those
tools in situations of unlimited liability.</p>
<p>Imagine parroting â€œinformationâ€ from a known liar in a context in which you, the
parrot (and/or the company) are fully responsible?  Polly want a lawsuit?</p>
<p>I left that presentation thinking that <abbr title="Large Language Models">LLMs</abbr>
 are <em>at best</em> a tarot card
reading; a voracious maw consuming water and humanityâ€™s corpus belching out
half-truths and heaps of carbon dioxide.  Fed both by the owners of the monster
but also the unpaid labor of the purveyors of wisdom and knowledge.</p>
<p>The owners that continue to train and tweak the monster to sound plausible.</p>
<p>And somewhere, I wish I could find it, someone recently added to that analogy;
namely that a growing reliance on <abbr title="Large Language Models">LLMs</abbr>
 for â€œthought completionâ€ is like an
escalating addiction to â€œgoing to a psychicâ€.  These <abbr title="Large Language Models">LLMs</abbr>
 are really good at
â€œcold readâ€ framing language.</p>
<blockquote class="quote epigraph" data-id="be-kind-to-our-language">
<p>
Be kind to our language.
</p>
<footer>&#8213;Timothy Snyder, <cite>On Tyranny</cite></footer></blockquote>
<p>Which is not to say psychic readings are bad; but when they substitute critical
thinking, they yield power to the psychic.  In the case of <abbr title="Large Language Models">LLMs</abbr>
, this is
yielding the agenda of the folks funding this looting of the commons.</p>
<p>A subset of folks Iâ€™m reading are writing about their personal fights against
the voracity of <abbr title="Large Language Models">LLMs</abbr>
 scraping the web.  With words like â€œButlerian Jihadâ€,
annubis, and iocane.  Thereâ€™s escalating attacks on technical infrastructure;
namely in the form of <a href="https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/">massive bombardment of open source providers</a>.</p>
<p>All of this because the remixing of our stories and knowledge feels like
something new, but is at best generative nostalgia.  <abbr title="Large Language Models">LLMs</abbr>
 are predictive
engines; what word/phrase likely follows the next based on statistics.</p>
<p>They are absolutely trash in regards to truth, but instead generate
plausibility; looting, perverting, and corrupting our collective shared
humanity.</p>
<p>There are certainly â€œvalidâ€ uses for <abbr title="Large Language Models">LLMs</abbr>
; just not â€œvibe codingâ€ and â€œvibe
writing.â€  Which leads me to a second presentation; one a few years earlier,
back when I worked in an academic library.</p>
<p>This was a presentation on the mathematics of subject analysis; the guts of the
presentation was the algorithm used for determining the â€œclosenessâ€ of a items
in a corpus to other items in a corpus.</p>
<p>The presenters spoke about using this as a tool to dig a bit deeper into
researching those relations.  Using the output as a bit of a divining rod that
might help find relationships to explore.  The language they used left me
thinking of approaching this output with a sense of mystery and curiosity.</p>
<blockquote class="quote epigraph" data-id="20230701T171924">
<p>
Men have become the tools of their tools.
</p>
<footer>&#8213;Henry David Thoreau, <cite>Walden</cite></footer></blockquote>
<p>In my personal writing, I do not use <abbr title="Large Language Models">LLMs</abbr>
.<small class="side-container">
  <span class="side-label"><span class="hidden">(</span>Sidenote<span class="hidden">:</span></span>
  <span class="side" role="note"> Though there was a time several years ago when I used Grammarly, as an
editor of my writing.  But no more.<span class="hidden">)</span></span>
</small>
 I might want to â€œthink fasterâ€ and
have felt a compulsion to â€œwrite fasterâ€; but I donâ€™t conflate that desire with
using a tool as my thinkingâ€¦and claiming that copy/paste as my thinking.</p>
<p>After all, I write to think.  And the very process of thinking, slowing down,
and teasing out those ideas, is for me, a classic human experience.  Iâ€™m
interested in the â€œfinished productâ€ but even more, the process of getting there.</p>
<h2 id="postscript">Postscript</h2>
<p>Given that weâ€™re seeing high-stakes usage of <abbr title="Large Language Models">LLMs</abbr>
 as decision making
instruments, Iâ€™d recommend giving a read of <a href="https://emsenn.substack.com/p/governing-by-confusion">Governing by Confusion</a>.  Its not
about <abbr title="Large Language Models">LLMs</abbr>
 but is an excellent paper on inter-connected systems, and the concept
of closing the loop through participatory reflection.</p>

	<p><a class="reply-by-email" href="mailto:reply-to@takeonrules.com?subject=RE:Raiding%20Parties">Reply by Email</a></p>

      