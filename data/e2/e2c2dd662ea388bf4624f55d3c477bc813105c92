<div class="media-wrapper"><img decoding="async" src="https://cdn.macstories.net/cleanshot-2025-10-15-at-21-49-18-2x-1760557775110.png" alt=""><p class="image-caption"></p></div>
<p id="p2">Earlier today, Anthropic released Haiku 4.5, a new version of their &ldquo;small and fast&rdquo; model that matches Sonnet 4 performance from five months ago at a fraction of the cost and twice the speed. From <a href="https://www.anthropic.com/news/claude-haiku-4-5" rel="noopener noreferrer">their announcement</a>:</p>
<blockquote id="blockquote3"><p>
  What was recently at the frontier is now cheaper and faster. Five months ago, Claude Sonnet 4 was a state-of-the-art model. Today, Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed.
</p></blockquote>
<p id="p4">And:</p>
<blockquote id="blockquote5"><p>
  Claude Sonnet 4.5, released&nbsp;<a href="https://www.anthropic.com/news/claude-sonnet-4-5" rel="noopener noreferrer">two weeks ago</a>, remains our frontier model and the best coding model in the world. Claude Haiku 4.5 gives users a new option for when they want near-frontier performance with much greater cost-efficiency. It also opens up new ways of using our models together. For example, Sonnet 4.5 can break down a complex problem into multi-step plans, then orchestrate a team of multiple Haiku 4.5s to complete subtasks in parallel.
</p></blockquote>
<p id="p6">I&rsquo;m not a programmer, so I&rsquo;m not particularly interested in benchmarks for coding tasks and <a href="https://www.claude.com/product/claude-code" rel="noopener noreferrer">Claude Code</a> integrations. However, as I explained in <a href="https://appstories.net/episodes/455" rel="noopener noreferrer">this Plus segment of AppStories for members</a>, I&rsquo;m very keen to play around with fast models that considerably reduce inference times to allow for quicker back and forth in conversations. As I detailed on AppStories, I&rsquo;ve had a solid experience with <a href="https://www.cerebras.ai/" rel="noopener noreferrer">Cerebras</a> and <a href="https://boltai.com/" rel="noopener noreferrer">Bolt for Mac</a> to generate responses at over 1,000 tokens per second.</p>
<p id="p7">I have a personal test that I like to try with all modern LLMs that support MCP: how quickly they can append the word &ldquo;Test&rdquo; to my daily note in Notion. Based on a few experiments I ran earlier today, Haiku 4.5 seems to be the new state of the art for both following instructions and speed in this simple test.</p>
<p id="p8">I ran my tests with LLMs that support MCP-based connectors: Claude and <a href="https://mistral.ai/news/le-chat-mcp-connectors-memories" rel="noopener noreferrer">Mistral</a>. Both were given system-level instructions on how to access my daily notes: Claude had the details in its <a href="https://support.claude.com/en/articles/10185728-understanding-claude-s-personalization-features#" rel="noopener noreferrer">profile personalization screen</a>; in Mistral, I created a dedicated <a href="https://help.mistral.ai/en/articles/347482-what-s-an-agent-and-how-do-i-create-one" rel="noopener noreferrer">agent</a> with Notion instructions. So, all things being equal, here&rsquo;s how long it took three different, non-thinking models to run my command:</p>
<ul id="ul9"><li>Mistral: 37 seconds</li>
<li>Claude Sonnet 4.5: 47 seconds</li>
<li>Claude Haiku 4.5: 18 seconds</li>
</ul><p id="p10">That is a drastic latency reduction compared to Sonnet 4.5, and it&rsquo;s especially impressive when we consider how Mistral is using <a href="https://www.cerebras.ai/blog/mistral-le-chat" rel="noopener noreferrer">Flash Answers</a>, which is fast inference powered by Cerebras. As I shared on AppStories, it seems to <a href="https://developer.nvidia.com/blog/how-small-language-models-are-key-to-scalable-agentic-ai/" rel="noopener noreferrer">confirm</a> that it&rsquo;s possible to have speed and reliability for agentic tool-calling without having to use a large model.</p>
<p id="p11">I ran other tests with Haiku 4.5 and the Todoist MCP and, similarly, I was able to mark tasks as completed and reschedule them in seconds, with none of the latency I previously observed in Sonnet 4.5 and Opus 4.1. As it stands now, if you&rsquo;re interested in <a href="https://www.macstories.net/notes/llms-for-data-portability/" rel="noopener noreferrer">using LLMs with apps and connectors</a> without having to wait around too long for responses and actions, Haiku 4.5 is the model to try.</p>
<hr /><h3>Access Extra Content and Perks</h3><p><p>Founded in 2015, <a href="https://club.macstories.net/plans?utm_source=ms&amp;utm_medium=web-inline" rel="noopener noreferrer">Club MacStories</a> has delivered exclusive content every week for nearly a decade.</p>
<p>What started with weekly and monthly email newsletters has blossomed into <a href="https://club.macstories.net/plans?utm_source=ms&amp;utm_medium=web-inline" rel="noopener noreferrer">a family of memberships</a> designed every MacStories fan.</p>
<p><strong><a href="https://club.macstories.net/plans/club" rel="noopener noreferrer">Club MacStories</a></strong>: Weekly and monthly newsletters via email and the web that are brimming with apps, tips, automation workflows, longform writing, early access to the <a href="https://www.macstories.net/unwind/" rel="noopener noreferrer">MacStories Unwind podcast</a>, periodic giveaways, and more;</p>
<p><strong><a href="https://club.macstories.net/plans/plus" rel="noopener noreferrer">Club MacStories+</a></strong>: Everything that Club MacStories offers, plus an active Discord community, advanced search and custom RSS features for exploring the Club&rsquo;s entire back catalog, bonus columns, and dozens of app discounts;</p>
<p><strong><a href="https://club.macstories.net/plans/premier" rel="noopener noreferrer">Club Premier</a></strong>: All of the above <em>and</em> AppStories+, an extended version of our flagship podcast that&rsquo;s delivered early, ad-free, and in high-bitrate audio.</p>
<p>Learn more <a href="https://club.macstories.net/plans?utm_source=ms&amp;utm_medium=web-inline" rel="noopener noreferrer">here</a> and from our <a href="https://club.macstories.net/faq" rel="noopener noreferrer">Club FAQs</a>.</p>
</p><a href='https://club.macstories.net/?utm_source=ms&#038;utm_medium=rss'>Join Now</a>